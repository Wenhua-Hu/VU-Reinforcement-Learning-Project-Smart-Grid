{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7549b86",
   "metadata": {},
   "source": [
    "# Reinforcement learning practical sessions - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb46de00",
   "metadata": {},
   "source": [
    "## Workshop tutorial, day 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55dd0d8",
   "metadata": {},
   "source": [
    "## Deep Reinforcement Learning Agent (Part 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5dc2ee",
   "metadata": {},
   "source": [
    "### Author: Buelent Uendes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879505c9",
   "metadata": {},
   "source": [
    "In this notebook, we will use a function approximator to solve the mountain car game. As seen in the previous notebook, a simple agent that uses Q learning can learn to move the car in a way to move up the hill. Yet, for this to work, one had to discretize the state space. However, for large problems this approach is not feasible, given the fact that we then have a state,action pair matrix. To overcome this, we will use a Neural Network that will approximate the state, pair values. For this, we will use PyTorch. If you have not used PyTorch yet, do not worry, as most of the code will be provided for you. Also, you can always ask any TA for further help. Yet, if you want to have a more in-depth tutorial in PyTorch, you can use the following YouTube tutorial:\n",
    "\n",
    "- https://www.youtube.com/watch?v=c36lUUr864M\n",
    "\n",
    "Deep reinforcement learning got popular following the paper published in 2013 [Playing Atari with Deep Reinforcement Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf). Following this paper, several additional techniques were introduced that aim to stabilize the learning process. In the following notebook, we will look at two new methods, memory replay and target networks and will try to solve the mountain car environment using a Deep Reinforcement Learning algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ef6ad",
   "metadata": {},
   "source": [
    "**The code used in this notebook is based upon the implementation of a Deep Q agent as shown in this [tutorial.](https://www.youtube.com/watch?v=NP8pXZdU-5U)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e0072",
   "metadata": {},
   "source": [
    "**Instructions:**\n",
    "\n",
    "In the notebook, you will see a couple of ToDos with some instructions. Try your best to work through them and to complete the notebook. In case you run into problems, do not hesitate to ask any of the TAs for help! :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5bd33c",
   "metadata": {},
   "source": [
    "## Preliminaries "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c663abf",
   "metadata": {},
   "source": [
    "### Import main libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c56bb551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, MultiDiscrete, Tuple\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa54dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from collections import deque\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d44435",
   "metadata": {},
   "source": [
    "### Seeting the seed for reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76efac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "seed = 7\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b8108",
   "metadata": {},
   "source": [
    "## General notes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1f4fab",
   "metadata": {},
   "source": [
    "We will introduce the concept of Deep Reinforcement Learning in **three** steps:\n",
    "\n",
    "1) First introduce how to implement a simple deep neural network that is represents an essential building block of Deep Q learning\n",
    "\n",
    "2) Introduce the topic of experience replay/replay buffer\n",
    "\n",
    "3) Introduce the concept of a target network!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f29625",
   "metadata": {},
   "source": [
    "## Part 1: Deep neural network and its general characteristics in the context of reinforcement learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01122b51",
   "metadata": {},
   "source": [
    "### General characteristics of Deep Q learning\n",
    "\n",
    "In the simplest approach, a Deep RL algorithm is:\n",
    "\n",
    "- Episodic (the agent acts in the environment only for a specific number of timesteps)\n",
    "- Online (we train the algorithm while the agent interacts with the environment)\n",
    "- Model-free. We do not attempt to model the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc3b72",
   "metadata": {},
   "source": [
    "In the following, we will implement a deep neural network using the PyTorch library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2b05200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 make the step function go through one hour at a time, and through the entire dataframe (sequentially) in total *\n",
    "# 2 take at_home out of the state *\n",
    "# 3 include the action mechanics inside of the step function *\n",
    "# 4 test environment again on random policy loop *\n",
    "# 5 try q learning\n",
    "# 6 change action to -1, 1 range *\n",
    "# 7 change reward calculation *\n",
    "# 8 test with the test environment (validate using main.py)\n",
    "# 9 include electricity price, and maybe more time elements in the state representation (week/month/year)\n",
    "# 10 change hour from 08-07 to 01-00 *\n",
    "\n",
    "### contuinuous action mechanism:\n",
    "# action comes in in continuous form in training loop, is modified in the step function in continuous form within range [-1,1], which\n",
    "# is used then to update state variables, i.e. battery level, into a continuous variable between [0,50]\n",
    "# state is returned in continuous form\n",
    "# in tabular Q learning, state (from env.step) is taken and discretized to get next action\n",
    "# in approximator methods, state is taken as continuous and used to get next action\n",
    "\n",
    "class StorageEnv(Env):\n",
    "    def __init__(self, path_to_train_data):\n",
    "        '''\n",
    "        Initialization of the energy storage environment;\n",
    "        We interpret a run through all historical price data as one trajectory = one episode,\n",
    "        where for each hour of each day, we can run the step function to update from one state\n",
    "        to the next, given some action for that hour (the step function will return the next\n",
    "        state, as well as next reward, and whether the entire historical dataset has been\n",
    "        iterated through using the 'done' variable in the return statement).\n",
    "        '''\n",
    "\n",
    "        self.train_data = pd.read_excel(path_to_train_data)\n",
    "        self.price_values = self.train_data.iloc[:, 1:25].to_numpy()\n",
    "        self.timestamps = self.train_data['PRICES']\n",
    "        self.state = np.empty(5)\n",
    "        # self.nr_hours = self.price_values.shape[0]*self.price_values.shape[1] # number of hours in the dataset in total = 25208 for train.xlsx\n",
    "        self.nr_hours = np.size(self.price_values)\n",
    "        # print(self.nr_hours)\n",
    "\n",
    "        self.battery_range = Box(low=0, high=50, shape=(1,), dtype=np.float32)\n",
    "        self.hour_range = Discrete(24, start=1)\n",
    "        self.position_range = Discrete(2)\n",
    "        self.dow_range = Discrete(7)\n",
    "        self.month_range = Discrete(12, start=1)\n",
    "        # obv space: battery level from 0 to 50 (continuous), hour of the dayt\n",
    "        self.observation_space = Tuple((self.battery_range, self.hour_range, self.position_range,self.dow_range,self.month_range))\n",
    "\n",
    "        self.action_space = np.array([-1.0, -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1,  0 , 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1.0 ])\n",
    "        # self.actions = Discrete(len(self.action_repr))\n",
    "        self.action_space_n = len(self.action_space)\n",
    "        \n",
    "        self.action2indices = {}\n",
    "        self.index2actions = {}\n",
    "        for i in range(self.action_space_n):\n",
    "            self.index2actions[i] = self.action_space[i]\n",
    "            self.action2indices[self.action_space[i]] = i \n",
    "        \n",
    "        # self.action_space = Discrete(21, start=-2) # -1 -0.9 8 7 6 5 4 3 2 1 0 1 2 \n",
    "        self.cont_action_space = Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        # self.action_repr = [-2,-1,0,1,2]\n",
    "\n",
    "        # self.position_space = Discrete(2, start=0)\n",
    "\n",
    "        # self.done = False # indicates whether trajectory (run through entire dataset) has finished, analogous to 'terminated' argument\n",
    "        \n",
    "        # self.min_battery_level_start = 20  #minimum_morning_level\n",
    "        # self.min_battery_level = 0\n",
    "        # self.max_battery_level = 50   #battery_capacity\n",
    "        # self.max_charging_level = 25\n",
    "        \n",
    "        # Battery characteristics\n",
    "        self.battery_capacity = 50  # kWh\n",
    "        self.max_power = 25 / 0.9  # kW\n",
    "        self.charge_efficiency = 0.9  # -\n",
    "        self.discharge_efficiency = 0.9  # -\n",
    "        # self.battery_level = self.battery_capacity / 2  # kWh (start at 50%)\n",
    "        self.minimum_morning_level = 20  # kWh\n",
    "        self.car_use_consumption = 20  # kWh\n",
    "\n",
    "        # Time Tracking\n",
    "        # self.counter = 0\n",
    "        # self.hour = 1\n",
    "        # self.day = 1\n",
    "        # self.car_is_available = True\n",
    "\n",
    "        # initialize state vars\n",
    "        # self.battery_level = np.random.uniform(self.min_battery_level_start, self.max_battery_level) # continuous value between 20 and 50\n",
    "        # randomly initialize athome with 50/50 chance of being away at hour 0 (8am) or not\n",
    "        # self.at_home = np.random.randint(self.position_space.n) # 50% chance at home at start of each day\n",
    "        # initial state\n",
    "        # self.state = np.array([self.battery_level, self.hour])\n",
    "        \n",
    "\n",
    "\n",
    "    def step(self, action): # action is between -1 and 1\n",
    "        action = np.squeeze(action)\n",
    "        # print(action)\n",
    "        ######### at current timestep t\n",
    "        ### battery comsumption at timestep t\n",
    "        \n",
    "        if action <-1 or action >1:\n",
    "            raise ValueError('Action must be between -1 and 1')\n",
    "        \n",
    "        # store the action into action_bs\n",
    "        action_bs = action\n",
    "        # Calculate if, at 7am and after the chosen action, the battery level will be below the minimum morning level:\n",
    "        penalty = 0.0 # peality\n",
    "        if self.hour == 7:\n",
    "            if action > 0 and (self.battery_level < self.minimum_morning_level):\n",
    "                if (\n",
    "                        self.battery_level + action * self.max_power * self.charge_efficiency) < self.minimum_morning_level:  # If the chosen action will not charge the battery to 20kWh\n",
    "                    action = (self.minimum_morning_level - self.battery_level) / (\n",
    "                                self.max_power * self.charge_efficiency)  # Charge until 20kWh\n",
    "                    # charge higher to nearest legal action\n",
    "                    action = math.ceil(action * 10.0) / 10.0\n",
    "\n",
    "            elif action < 0:\n",
    "                if (self.battery_level + action * self.max_power) < self.minimum_morning_level:\n",
    "                    if self.battery_level < self.minimum_morning_level:  # If the level was lower than 20kWh, charge until 20kWh\n",
    "                        action = (self.minimum_morning_level - self.battery_level) / (\n",
    "                                    self.max_power * self.charge_efficiency)  # Charge until 20kWh\n",
    "                        # charge higher to nearest legal action\n",
    "                        action = math.ceil(action * 10.0) / 10.0\n",
    "                    elif self.battery_level >= self.minimum_morning_level:  # If the level was higher than 20kWh, discharge until 20kWh\n",
    "                        action = (self.minimum_morning_level - self.battery_level) / (\n",
    "                            self.max_power)  # Discharge until 20kWh\n",
    "                        # discharge less to keep higher than 20kwh\n",
    "                        action = math.ceil(action * 10.0) / 10.0\n",
    "            elif action == 0:\n",
    "                if self.battery_level < self.minimum_morning_level:\n",
    "                    action = (self.minimum_morning_level - self.battery_level) / (\n",
    "                                self.max_power * self.charge_efficiency)\n",
    "                    # charge higher to nearest legal action\n",
    "                    action = math.ceil(action * 10.0) / 10.0\n",
    "                    \n",
    "        if abs(action_bs - action) != 0:   \n",
    "            #* np.exp(abs(action_bs - action))\n",
    "            penalty += 10000.0\n",
    "\n",
    "        # if it is 8am, decide whether car will go away or stay (by random chance)\n",
    "        if self.hour == 8:\n",
    "            # self.car_is_available = np.random.choice([True, False])\n",
    "            if not self.car_is_available:\n",
    "                self.battery_level -= self.car_use_consumption\n",
    "                \n",
    "        # if self.hour == 18:\n",
    "        #     self.car_is_available = True\n",
    "            \n",
    "        # convert action [-1,1] to actual kwh charging (transform to [-25,25])\n",
    "        # if action > 0:\n",
    "        #   action = action * self.max_power * self.charge_efficiency\n",
    "        # # action = action * self.max_charging_level # now action lies in [-25,25]\n",
    "        # else:\n",
    "        #   action = action * self.max_power\n",
    "\n",
    "        # no charging/discharging if car is away, besides reduction of batter level by 20kwh at 8am (enforced later on)\n",
    "        if not self.car_is_available: # check if car is currently away, enforced by overriding previous if statement\n",
    "            action = 0\n",
    "            if abs(action_bs - action) != 0:   \n",
    "                #* np.exp(abs(action_bs - action))\n",
    "                penalty += 10000.0\n",
    "\n",
    "\n",
    "        # Calculate the costs and battery level when charging (action >0)\n",
    "        if (action > 0) and (self.battery_level <= self.battery_capacity):\n",
    "            if (self.battery_level + action * self.max_power * self.charge_efficiency) > self.battery_capacity:\n",
    "                action = (self.battery_capacity - self.battery_level) / (self.max_power * self.charge_efficiency)\n",
    "                # charge less to nearest legal action\n",
    "                action = math.floor(action * 10.0) / 10.0\n",
    "            charged_electricity_kW = action * self.max_power\n",
    "            charged_electricity_costs = charged_electricity_kW * self.price_values[self.day - 1][\n",
    "                self.hour - 1] * 2 * 1e-3\n",
    "            if abs(action_bs - action) != 0:\n",
    "                penalty += 10000.0\n",
    "            reward = -charged_electricity_costs - penalty\n",
    "            self.battery_level += charged_electricity_kW * self.charge_efficiency\n",
    "\n",
    "        # Calculate the profits and battery level when discharging (action <0)\n",
    "        elif (action < 0) and (self.battery_level >= 0):\n",
    "            if (self.battery_level + action * self.max_power) < 0:\n",
    "                action = -self.battery_level / (self.max_power)\n",
    "                # discharge less to nearest legal action\n",
    "                action = math.ceil(action * 10.0) / 10.0\n",
    "            if abs(action_bs - action) != 0:\n",
    "                penalty += 10000.0\n",
    "                \n",
    "            discharged_electricity_kWh = action * self.max_power  # Negative discharge value\n",
    "            discharged_electricity_profits = abs(discharged_electricity_kWh) * self.discharge_efficiency * \\\n",
    "                                             self.price_values[self.day - 1][self.hour - 1] * 1e-3\n",
    "                                             \n",
    "            reward = discharged_electricity_profits - penalty\n",
    "            self.battery_level += discharged_electricity_kWh\n",
    "            # Some small numerical errors causing the battery level to be 1e-14 to 1e-17 under 0 :\n",
    "            if self.battery_level < 0:\n",
    "                self.battery_level = 0\n",
    "\n",
    "        else:\n",
    "            reward = 0\n",
    "            \n",
    "\n",
    "        # # meeting constraints of having 20kwh at 7am, and alwys more than 0kwh stored\n",
    "        # if self.car_is_available:\n",
    "        #   low = self.cont_action_space.low[0]\n",
    "        #   high = self.cont_action_space.high[0]\n",
    "        #   # calculate the exact action you need to get the battery to 20kwh, by taking the min of all sufficient (=legal) actions\n",
    "        #   if self.hour == 7: # adapt legal action calculating functions\n",
    "        #     legal_actions = get_legal_range([low, high], self.battery_level, min_level = 20)\n",
    "        #     if not (legal_actions[0] <= action <= legal_actions[1]): # check if action chosen by agent ensures 20kwh of battery at 7am\n",
    "        #       action = legal_actions[0] # charge needed for 20kwh, if initial action would result in <20 charge\n",
    "        #   # rest of the day, ensure that battery stays above or at 0kwh\n",
    "        #   else:\n",
    "        #     legal_actions = get_legal_range([self.cont_action_space.low[0], self.cont_action_space.high[0]], self.battery_level, min_level=0)\n",
    "        #     if not (legal_actions[0] <= action <= legal_actions[1]): # check if action chosen by agent ensures >=0kwh of battery at 7am\n",
    "        #       action = legal_actions[0] # charge needed to have positive >=0kwh charge, if initial action would result in negative <0kwh\n",
    "\n",
    "        # removing 20kwh from battery when going away from home\n",
    "        # if not self.car_is_available:\n",
    "        #   self.battery_level = self.battery_level - 20 if self.hour == 8 else self.battery_level\n",
    "\n",
    "        # update battery level based on the picked acion at timestep t\n",
    "        # if self.car_is_available:\n",
    "        #     self.battery_level += action\n",
    "\n",
    "        # no over-charging above 50kwh\n",
    "        # if self.battery_level >= 50:\n",
    "        #     self.battery_level = 50\n",
    "\n",
    "        # should we move the constraints not lower 0 here ??\n",
    "\n",
    "        ######### update the state for next hour, timestep t+1\n",
    "        # keep the hour 8 ~ 18 same, otherwise athome = True\n",
    "        # self.car_is_available = self.car_is_available if 8 <= self.hour < 18 else 1 # TO-DO: check if this should not be <= 18 instead\n",
    "\n",
    "        # reward calculations\n",
    "        # hourly_price = self.price_values[self.day-1][self.hour-1]\n",
    "        # cost_factor = 1.0 if action < 0 else 2.0\n",
    "        # efficiency_price_factor = 0.9 if action < 0 else 1.0 # obtained electricity is impacted by 0.9 when selling\n",
    "\n",
    "        # get amount of kwh bought during this step\n",
    "        # kwhs_charged = action # just for reading clarity\n",
    "        # price_of_charging = kwhs_charged * cost_factor * efficiency_price_factor * (hourly_price/1000) # go from MWh to KWh, multiply by 2 if we are buying\n",
    "        # # reward, based on current price from table\n",
    "        # reward = (-1.) * price_of_charging # reward for this step, positive if selling, negative when buying\n",
    "\n",
    "        # update counter and time variables\n",
    "        self.counter += 1 # update continuous counter (running from 0 - len(df)*24)\n",
    "        self.hour += 1 # increment hour (running from 1-24 and back to 1 after the day passed)\n",
    "\n",
    "        if self.counter % 24 == 0: # check if day is over, meaning that it is midnight at timestep t+1\n",
    "            self.hour = 1 # reset hour of the day for next timestep\n",
    "            self.day += 1 # increment to start of next day\n",
    "             \n",
    "        if self.hour == 8:\n",
    "            self.car_is_available = np.random.choice([True, False])\n",
    "    \n",
    "        if self.hour == 18:\n",
    "            self.car_is_available = True\n",
    "\n",
    "        # update state\n",
    "        self.state = self.observation()\n",
    "\n",
    "\n",
    "        # check if all hours in the dataset have been seen\n",
    "        terminated = self.counter == self.nr_hours - 1\n",
    "        truncated = False\n",
    "        info = action\n",
    "\n",
    "        return self.state, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "      \n",
    "    def observation(self):  # Returns the current state\n",
    "        battery_level = self.battery_level\n",
    "        price = self.price_values[self.day - 1][self.hour - 1]\n",
    "        hour = self.hour\n",
    "        day_of_week = self.timestamps[self.day - 1].dayofweek  # Monday = 0, Sunday = 6\n",
    "        day_of_year = self.timestamps[self.day - 1].dayofyear  # January 1st = 1, December 31st = 365\n",
    "        month = self.timestamps[self.day - 1].month  # January = 1, December = 12\n",
    "        year = self.timestamps[self.day - 1].year\n",
    "        self.state = np.array([\n",
    "              battery_level, \n",
    "              #price, \n",
    "              int(hour), \n",
    "              int(self.car_is_available),\n",
    "              int(day_of_week), \n",
    "              #int(day_of_year), \n",
    "              int(month), \n",
    "              #int(year),\n",
    "             ])\n",
    "        # if match  \n",
    "        # print(self.state)\n",
    "        # print(f\"{self.timestamps[self.day - 1]} --   {day_of_week}\")\n",
    "        return self.state\n",
    "\n",
    "    def reset(self):\n",
    "      self.done = False # indicates whether trajectory (run through entire dataset) has finished, analogous to 'terminated' argument\n",
    "      self.counter = 0\n",
    "      self.hour = 1\n",
    "      self.day = 1\n",
    "      # self.car_is_available = True\n",
    "      # self.at_home = self.car_is_available  \n",
    "\n",
    "        # resetting battery charge state var, random re-initialization between 0 and 50kwh\n",
    "        #   if self.hour == 8:\n",
    "        #     self.battery_level = np.random.uniform(self.minimum_morning_level, self.battery_capacity) # continuous value between 20 and 50\n",
    "        #   elif 8 < self.hour <= 18:\n",
    "        #     self.battery_level = np.random.uniform(0, self.battery_capacity-self.minimum_morning_level) # continuous value between 20 and 50\n",
    "        #   else:\n",
    "      self.battery_level = np.random.uniform(0, self.battery_capacity) # continuous value between 0 and 50\n",
    "        \n",
    "      # randomly re-initialize athome with 50/50 chance of being away at hour 0 (8am) or not\n",
    "\n",
    "      self.car_is_available = True  # np.random.randint(self.position_space.n) # 50% chance at home at start of each day\n",
    "      # new initial state\n",
    "      self.state = self.observation()\n",
    "    #   self.state = np.array([self.battery_level, self.hour])\n",
    "\n",
    "      return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e48f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \n",
    "    def __init__(self, env, learning_rate):\n",
    "        \n",
    "        '''\n",
    "        Params:\n",
    "        env = environment that the agent needs to play\n",
    "        learning_rate = learning rate used in the update\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        super(DQN,self).__init__()\n",
    "        # input_features = env.observation_space.shape[0]\n",
    "        input_features = len(env.observation_space)\n",
    "        action_space = env.action_space_n\n",
    "        \n",
    "        '''\n",
    "        ToDo: \n",
    "        Write the layers of your neural network! \n",
    "        Make sure that the input features and the output features are in line with the environment that \n",
    "        the class takes as an input feature\n",
    "        '''\n",
    "        #Solution:\n",
    "        \n",
    "        self.dense1 = nn.Linear(in_features = input_features, out_features = 128)\n",
    "        self.dense2 = nn.Linear(in_features = 128, out_features = 64)\n",
    "        self.dense3 = nn.Linear(in_features = 64, out_features = 32)\n",
    "        self.dense4 = nn.Linear(in_features = 32, out_features = action_space)\n",
    "        \n",
    "        #Here we use ADAM, but you could also think of other algorithms such as RMSprob\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr = learning_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        '''\n",
    "        Params:\n",
    "        x = observation\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        ToDo: \n",
    "        Write the forward pass! You can use any activation function that you want (ReLU, tanh)...\n",
    "        Important: We want to output a linear activation function as we need the q-values associated with each action\n",
    "    \n",
    "        '''\n",
    "        \n",
    "        #Solution:\n",
    "        x = torch.tanh(self.dense1(x))\n",
    "        x = torch.tanh(self.dense2(x))\n",
    "        x = torch.tanh(self.dense3(x))\n",
    "        x = self.dense4(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32692ba5",
   "metadata": {},
   "source": [
    "That's it! This is the implementation of a deep neural network in PyTorch!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc5db9",
   "metadata": {},
   "source": [
    "## Part 2: Experience replay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618bcd95",
   "metadata": {},
   "source": [
    "In a normal implementation of a deep neural network, one would train the algorithm using some sort of a gradient method. Yet, one of the key assumption is that the data is iid, i.e. independent identically distributed which does not hold in our reinforcement learning setting. The next state and its reward depends on the action our agent took the preceeding state which makes subsequent states and the data highly correlated. This can cause the DQN to be instable. To circumvent this, people use in practice a so-called experience replay technique. The main rationale behind this idea is to break the correlation between subsequent transitions by saving experiences in memory and sample randomly from the stored transitions when performing a Q-value update. This 'trick' is essential to make the method work!\n",
    "\n",
    "In the following, we will create a experience replay class that will store the transitions of the deep Q agent. It is important to keep in mind that the replay buffer has a fixed capacity. If the data that we want to store in the replay buffer exceeds the buffer, we want to store only the most recent transitions in the buffer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f13b6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay:\n",
    "    \n",
    "    def __init__(self, env, buffer_size, min_replay_size = 1000, seed = 123):\n",
    "        \n",
    "        '''\n",
    "        Params:\n",
    "        env = environment that the agent needs to play\n",
    "        buffer_size = max number of transitions that the experience replay buffer can store\n",
    "        min_replay_size = min number of (random) transitions that the replay buffer needs to have when initialized\n",
    "        seed = seed for random number generator for reproducibility\n",
    "        '''\n",
    "        self.env = env\n",
    "        self.min_replay_size = min_replay_size\n",
    "        self.replay_buffer = deque(maxlen=buffer_size)\n",
    "        self.reward_buffer = deque([-200.0], maxlen = 100)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        print('Please wait, the experience replay buffer will be filled with random transitions')\n",
    "                \n",
    "        # obs, _ = self.env.reset(seed=seed)\n",
    "        obs = self.env.reset()\n",
    "        for _ in range(self.min_replay_size):\n",
    "            '''\n",
    "            ToDo: \n",
    "            Write a for loop that initializes the experience replay buffer with random transitions \n",
    "            such that the experience replay buffer \n",
    "            has minimum random transitions already stored \n",
    "            '''\n",
    "            \n",
    "        #Solution:\n",
    "            # action = env.action_space.sample()\n",
    "            action = np.random.choice(self.env.action_space)\n",
    "            new_obs, rew, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "\n",
    "            transition = (obs, action, rew, done, new_obs)\n",
    "            self.replay_buffer.append(transition)\n",
    "            obs = new_obs\n",
    "    \n",
    "            if done:\n",
    "                # obs, _ = env.reset(seed=seed)\n",
    "                obs = env.reset()\n",
    "        \n",
    "        print('Initialization with random transitions is done!')\n",
    "      \n",
    "          \n",
    "    def add_data(self, data): \n",
    "        '''\n",
    "        Params:\n",
    "        data = relevant data of a transition, i.e. action, new_obs, reward, done\n",
    "        '''\n",
    "        self.replay_buffer.append(data)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        \n",
    "        '''\n",
    "        Params:\n",
    "        batch_size = number of transitions that will be sampled\n",
    "        \n",
    "        Returns:\n",
    "        tensor of observations, actions, rewards, done (boolean) and next observation \n",
    "        '''\n",
    "        \n",
    "        transitions = random.sample(self.replay_buffer, batch_size)\n",
    "        # print(transitions)\n",
    "        #Solution\n",
    "        observations = np.asarray([t[0] for t in transitions])\n",
    "        # print(observations)\n",
    "        actions = np.asarray([t[1] for t in transitions])\n",
    "        # print(actions)\n",
    "        rewards = np.asarray([t[2] for t in transitions])\n",
    "        dones = np.asarray([t[3] for t in transitions])\n",
    "        new_observations = np.asarray([t[4] for t in transitions])\n",
    "\n",
    "        #PyTorch needs these arrays as tensors!, don't forget to specify the device! (cpu / GPU)\n",
    "        observations_t = torch.as_tensor(observations, dtype = torch.float32, device=self.device)\n",
    "        actions_t = torch.as_tensor(actions, dtype = torch.float32, device=self.device).unsqueeze(-1)\n",
    "        rewards_t = torch.as_tensor(rewards, dtype = torch.float32, device=self.device).unsqueeze(-1)\n",
    "        dones_t = torch.as_tensor(dones, dtype = torch.float32, device=self.device).unsqueeze(-1)\n",
    "        new_observations_t = torch.as_tensor(new_observations, dtype = torch.float32, device=self.device)\n",
    "        # print(actions_t)\n",
    "        \n",
    "        return observations_t, actions_t, rewards_t, dones_t, new_observations_t\n",
    "    \n",
    "    def add_reward(self, reward):\n",
    "        \n",
    "        '''\n",
    "        Params:\n",
    "        reward = reward that the agent earned during an episode of a game\n",
    "        '''\n",
    "        \n",
    "        self.reward_buffer.append(reward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b2e24ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = StorageEnv(path_to_train_data=\"../../data/train.xlsx\")\n",
    "# replay_memory = ExperienceReplay(env, 50, seed = seed)\n",
    "# replay_memory.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62617a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5a756de",
   "metadata": {},
   "source": [
    "## Write the code for the vanilla DQN agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "29b36a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vanilla_DQNAgent:\n",
    "    \n",
    "    def __init__(self, env, device, epsilon_decay, \n",
    "                 epsilon_start, epsilon_end, discount_rate, lr, buffer_size, seed = 123):\n",
    "        '''\n",
    "        Params:\n",
    "        env = environment that the agent needs to play\n",
    "        device = set up to run CUDA operations\n",
    "        epsilon_decay = Decay period until epsilon start -> epsilon end\n",
    "        epsilon_start = starting value for the epsilon value\n",
    "        epsilon_end = ending value for the epsilon value\n",
    "        discount_rate = discount rate for future rewards\n",
    "        lr = learning rate\n",
    "        buffer_size = max number of transitions that the experience replay buffer can store\n",
    "        seed = seed for random number generator for reproducibility\n",
    "        '''\n",
    "        self.env = env\n",
    "        self.device = device\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_start = epsilon_start\n",
    "        self.epsilon_end = epsilon_end\n",
    "        self.discount_rate = discount_rate\n",
    "        self.learning_rate = lr\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        self.replay_memory = ExperienceReplay(self.env, self.buffer_size, seed = seed)\n",
    "        self.online_network = DQN(self.env, self.learning_rate).to(self.device)\n",
    "        \n",
    "    def choose_action(self, step, observation, greedy = False):\n",
    "        \n",
    "        '''\n",
    "        Params:\n",
    "        step = the specific step number \n",
    "        observation = observation input\n",
    "        greedy = boolean that\n",
    "        \n",
    "        Returns:\n",
    "        action: action chosen (either random or greedy)\n",
    "        epsilon: the epsilon value that was used \n",
    "        '''\n",
    "        \n",
    "        epsilon = np.interp(step, [0, self.epsilon_decay], [self.epsilon_start, self.epsilon_end])\n",
    "    \n",
    "        random_sample = random.random()\n",
    "    \n",
    "        if (random_sample <= epsilon) and not greedy:\n",
    "            #Random action\n",
    "            # action = self.env.action_space.sample()\n",
    "            action = np.random.choice(self.env.action_space)\n",
    "        \n",
    "        else:\n",
    "            #Greedy action\n",
    "            obs_t = torch.as_tensor(observation, dtype = torch.float32, device=self.device)\n",
    "            q_values = self.online_network(obs_t.unsqueeze(0))\n",
    "        \n",
    "            max_q_index = torch.argmax(q_values, dim = 1)[0]\n",
    "            action_i = max_q_index.detach().item()\n",
    "            # print(f\"action index {action_i}\")\n",
    "            action = self.env.index2actions[action_i]\n",
    "            # print(f\"action value {action}\")\n",
    "        return action, epsilon\n",
    "    \n",
    "    def learn(self, batch_size):\n",
    "        \n",
    "        '''\n",
    "        Params:\n",
    "        batch_size = number of transitions that will be sampled\n",
    "        '''\n",
    "        \n",
    "        #Sample random transitions with size = batch size\n",
    "        observations_t, actions_t, rewards_t, dones_t, new_observations_t = self.replay_memory.sample(batch_size)\n",
    "\n",
    "        target_q_values = self.online_network(new_observations_t)\n",
    "        max_target_q_values = target_q_values.max(dim=1, keepdim=True)[0]\n",
    "\n",
    "        targets = rewards_t + self.discount_rate * (1-dones_t) * max_target_q_values\n",
    "\n",
    "        #Compute loss\n",
    "        # print(actions_t.size())\n",
    "        # print(actions_t)\n",
    "        q_values = self.online_network(observations_t)\n",
    "        action_indices = self.env.action2indices\n",
    "        current_action_indices = []\n",
    "        for i in actions_t:\n",
    "            # action = i[0].item()\n",
    "            # action = i.item()\n",
    "            # print(action)\n",
    "            current_action_indices.append(action_indices[round(i.item(), 1)])\n",
    "            \n",
    "        indices = torch.as_tensor(current_action_indices)\n",
    "        indices_tensor = torch.unsqueeze(indices, 1)\n",
    "        # print(indices_tensor.size())\n",
    "            \n",
    "        action_q_values = torch.gather(input=q_values, dim=1, index=indices_tensor)\n",
    "\n",
    "        #Loss\n",
    "        \n",
    "        '''ToDo: \n",
    "        Implement here the loss function! You can choose the standard MSE loss or Huber loss. Call this variable loss!\n",
    "        '''\n",
    "        \n",
    "        #Solution: Here with the Huber loss\n",
    "        loss = F.smooth_l1_loss(action_q_values, targets.detach())\n",
    "        #Uncomment this line to use the standard MSE loss\n",
    "        #loss = F.mse_loss(action_q_values, targets.detach())\n",
    "        '''\n",
    "        ToDo: Write the gradient descent step, were you optimize the online network based on the loss!'\n",
    "        '''\n",
    "        \n",
    "        #Solution:\n",
    "        #Gradient descent\n",
    "        self.online_network.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.online_network.optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eceee3",
   "metadata": {},
   "source": [
    "## Write the training loop and perform the first run!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e78d68",
   "metadata": {},
   "source": [
    "In a last step, we can write a training loop that will put all things together. We will run the training loop for a number of iteration and see how our first algorithm performs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cae3b0",
   "metadata": {},
   "source": [
    "### Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40b0f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the hyperparameters\n",
    "\n",
    "#Discount rate\n",
    "discount_rate = 0.99\n",
    "#That is the sample that we consider to update our algorithm\n",
    "batch_size = 32\n",
    "#Maximum number of transitions that we store in the buffer\n",
    "buffer_size = 500# 50000\n",
    "#Minimum number of random transitions stored in the replay buffer\n",
    "min_replay_size = 100 #1000\n",
    "#Starting value of epsilon\n",
    "epsilon_start = 1.0\n",
    "#End value (lowest value) of epsilon\n",
    "epsilon_end = 0.05\n",
    "#Decay period until epsilon start -> epsilon end\n",
    "epsilon_decay = 10 #10000\n",
    "\n",
    "max_episodes = 250 #250000\n",
    "\n",
    "#Learning_rate\n",
    "lr = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d947bf",
   "metadata": {},
   "source": [
    "### Initialize all instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ecf59524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait, the experience replay buffer will be filled with random transitions\n",
      "Initialization with random transitions is done!\n"
     ]
    }
   ],
   "source": [
    "# env_name = 'MountainCar-v0'\n",
    "env = StorageEnv(path_to_train_data=\"../../data/train.xlsx\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vanilla_agent = vanilla_DQNAgent(env, device, epsilon_decay, epsilon_start, epsilon_end, discount_rate, lr, buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1bd29624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"MountainCar-v0\", render_mode = None)\n",
    "# print(type(env.observation_space), env.observation_space.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f68caa4",
   "metadata": {},
   "source": [
    "### Write a training loop function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ad5b08",
   "metadata": {},
   "source": [
    "We will first write a training loop function and let it then run for the vanilla DQN agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5c999f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(env, agent, max_episodes, target_ = False, seed=42):\n",
    "    \n",
    "    '''\n",
    "    Params:\n",
    "    env = name of the environment that the agent needs to play\n",
    "    agent= which agent is used to train\n",
    "    max_episodes = maximum number of games played\n",
    "    target = boolean variable indicating if a target network is used (this will be clear later)\n",
    "    seed = seed for random number generator for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    average_reward_list = a list of averaged rewards over 100 episodes of playing the game\n",
    "    '''\n",
    "    # env = gym.make(env_name, render_mode = None)\n",
    "    env = env\n",
    "    # env.action_space.seed(seed)  ### ???\n",
    "    # random.seed(seed)\n",
    "    random.shuffle(env.action_space)\n",
    "    obs = env.reset()\n",
    "    # obs, _ = env.reset(seed=seed)\n",
    "    average_reward_list = [-200]\n",
    "    episode_reward = 0.0\n",
    "    \n",
    "    for step in range(max_episodes):\n",
    "        \n",
    "        action, epsilon = agent.choose_action(step, obs)\n",
    "       \n",
    "        new_obs, rew, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated        \n",
    "        transition = (obs, action, rew, done, new_obs)\n",
    "        agent.replay_memory.add_data(transition)\n",
    "        obs = new_obs\n",
    "    \n",
    "        episode_reward += rew\n",
    "    \n",
    "        if done:\n",
    "        \n",
    "            # obs, _ = env.reset(seed=seed)\n",
    "            obs = env.reset()\n",
    "            agent.replay_memory.add_reward(episode_reward)\n",
    "            #Reinitilize the reward to 0.0 after the game is over\n",
    "            episode_reward = 0.0\n",
    "\n",
    "        #Learn\n",
    "\n",
    "        agent.learn(batch_size)\n",
    "\n",
    "        #Calculate after each 100 episodes an average that will be added to the list\n",
    "                \n",
    "        if (step+1) % 100 == 0:\n",
    "            average_reward_list.append(np.mean(agent.replay_memory.reward_buffer))\n",
    "        \n",
    "        #Update target network, do not bother about it now!\n",
    "        if target_:\n",
    "            \n",
    "            #Set the target_update_frequency\n",
    "            target_update_frequency = 250\n",
    "            if step % target_update_frequency == 0:\n",
    "                dagent.update_target_network()\n",
    "    \n",
    "        #Print some output\n",
    "        if (step+1) % 10000 == 0:\n",
    "            print(20*'--')\n",
    "            print('Step', step)\n",
    "            print('Epsilon', epsilon)\n",
    "            print('Avg Rew', np.mean(agent.replay_memory.reward_buffer))\n",
    "            print()\n",
    "\n",
    "    return average_reward_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0640da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rewards_vanilla_dqn = training_loop(env, vanilla_agent, max_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ad14c",
   "metadata": {},
   "source": [
    "**Comment**: As you can see, the vanilla deep Q network performs very poorly and does not learn to master the challenge. Play around with the number of iterations and epsilon decay to check if you can improve the algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd015ad5",
   "metadata": {},
   "source": [
    "## Part 3: Target network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9db3c",
   "metadata": {},
   "source": [
    "A problem of the standard Q learning introduced above is the fact that we use the same Q value to choose an action and to evaluate it. To overcome this problem, double-Q learning was proposed in the following paper [Double Q-learning](https://papers.nips.cc/paper/2010/file/091d584fced301b442654dd8c23b3fc9-Paper.pdf).\n",
    "In the case of DQN, we can make use of the same idea by training a second neural network,a so-called target network. Just as the name suggests, the target network will be used to compute the target of the update equation using this target network. This target network will only be updated after a pre-defined number of steps to ensure that the target will not move as the DQN network will learn (as it is the case in the standard simple DQN framework). This idea was put forward in the paper again by van Hasselt et al. (2016) [Deep reinforcement learning with double Q-learning](https://arxiv.org/pdf/1509.06461.pdf). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407fc05",
   "metadata": {},
   "source": [
    "Implementing a target network and changing the architecture to a double DQN is rather straightforward. All we need to do is to initialize besides an online network a so-called target network. After a specific number of steps, the parameter values of the target network are reinitialized with the online network after a pre-defined number of steps. For this, we will add a few lines to the vanilla DQN class and call it DDQN (for double deep Q learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4d870289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQNAgent:\n",
    "    \n",
    "    def __init__(self, env, device, epsilon_decay, \n",
    "                 epsilon_start, epsilon_end, discount_rate, lr, buffer_size, seed = 123):\n",
    "        '''\n",
    "        Params:\n",
    "        env = name of the environment that the agent needs to play\n",
    "        device = set up to run CUDA operations\n",
    "        epsilon_decay = Decay period until epsilon start -> epsilon end\n",
    "        epsilon_start = starting value for the epsilon value\n",
    "        epsilon_end = ending value for the epsilon value\n",
    "        discount_rate = discount rate for future rewards\n",
    "        lr = learning rate\n",
    "        buffer_size = max number of transitions that the experience replay buffer can store\n",
    "        seed = seed for random number generator for reproducibility\n",
    "        '''\n",
    "        self.env = env\n",
    "        self.device = device\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_start = epsilon_start\n",
    "        self.epsilon_end = epsilon_end\n",
    "        self.discount_rate = discount_rate\n",
    "        self.learning_rate = lr\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "        self.replay_memory = ExperienceReplay(self.env, self.buffer_size, seed = seed)\n",
    "        self.online_network = DQN(self.env, self.learning_rate).to(self.device)\n",
    "        \n",
    "        '''\n",
    "        ToDo: Add here a target network and set the parameter values to the ones of the online network!\n",
    "        Hint: Use the method 'load_state_dict'!\n",
    "        '''\n",
    "        \n",
    "        #Solution:\n",
    "        self.target_network = DQN(self.env, self.learning_rate).to(self.device)\n",
    "        self.target_network.load_state_dict(self.online_network.state_dict())\n",
    "        \n",
    "    def choose_action(self, step, observation, greedy = False):\n",
    "        \n",
    "        '''\n",
    "        Params:\n",
    "        step = the specific step number \n",
    "        observation = observation input\n",
    "        greedy = boolean that\n",
    "        \n",
    "        Returns:\n",
    "        action: action chosen (either random or greedy)\n",
    "        epsilon: the epsilon value that was used \n",
    "        '''\n",
    "        \n",
    "        epsilon = np.interp(step, [0, self.epsilon_decay], [self.epsilon_start, self.epsilon_end])\n",
    "    \n",
    "        random_sample = random.random()\n",
    "    \n",
    "        if (random_sample <= epsilon) and not greedy:\n",
    "            #Random action\n",
    "            # action = self.env.action_space.sample()\n",
    "            action = np.random.choice(self.env.action_space)\n",
    "        \n",
    "        else:\n",
    "            #Greedy action\n",
    "            obs_t = torch.as_tensor(observation, dtype = torch.float32, device=self.device)\n",
    "            q_values = self.online_network(obs_t.unsqueeze(0))\n",
    "        \n",
    "            max_q_index = torch.argmax(q_values, dim = 1)[0]\n",
    "            action_i = max_q_index.detach().item()\n",
    "            \n",
    "            action = self.env.index2actions[action_i]\n",
    "        \n",
    "        return action, epsilon\n",
    "    \n",
    "    \n",
    "    def return_q_value(self, observation):\n",
    "        '''\n",
    "        Params:\n",
    "        observation = input value of the state the agent is in\n",
    "        \n",
    "        Returns:\n",
    "        maximum q value \n",
    "        '''\n",
    "        #We will need this function later for plotting the 3D graph\n",
    "        \n",
    "        obs_t = torch.as_tensor(observation, dtype = torch.float32, device=self.device)\n",
    "        q_values = self.online_network(obs_t.unsqueeze(0))\n",
    "        \n",
    "        return torch.max(q_values).item()\n",
    "        \n",
    "    def learn(self, batch_size):\n",
    "        \n",
    "        '''\n",
    "        Params:\n",
    "        batch_size = number of transitions that will be sampled\n",
    "        '''\n",
    "        \n",
    "        observations_t, actions_t, rewards_t, dones_t, new_observations_t = self.replay_memory.sample(batch_size)\n",
    "\n",
    "\n",
    "        #Compute targets, note that we use the same neural network to do both! This will be changed later!\n",
    "\n",
    "        target_q_values = self.target_network(new_observations_t)\n",
    "        max_target_q_values = target_q_values.max(dim=1, keepdim=True)[0]\n",
    "\n",
    "        targets = rewards_t + self.discount_rate * (1-dones_t) * max_target_q_values\n",
    "\n",
    "        #Compute loss\n",
    "        q_values = self.online_network(observations_t)\n",
    "        action_indices = self.env.action2indices\n",
    "        current_action_indices = []\n",
    "        for i in actions_t:\n",
    "            # action = i.item()\n",
    "            current_action_indices.append(action_indices[round(i.item(), 1)])\n",
    "            \n",
    "        indices = torch.as_tensor(current_action_indices)\n",
    "        indices_tensor = torch.unsqueeze(indices, 1)\n",
    "        # print(indices_tensor.size())\n",
    "            \n",
    "        action_q_values = torch.gather(input=q_values, dim=1, index=indices_tensor)\n",
    "        #Loss, here we take the huber loss!\n",
    "\n",
    "        loss = F.smooth_l1_loss(action_q_values, targets)\n",
    "        \n",
    "        #Uncomment the following code to use the MSE loss instead!\n",
    "        #loss = F.mse_loss(action_q_values, targets)\n",
    "        \n",
    "        #Gradient descent to update the weights of the neural networ\n",
    "        self.online_network.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.online_network.optimizer.step()\n",
    "        \n",
    "    def update_target_network(self):\n",
    "        \n",
    "        '''\n",
    "        ToDO: \n",
    "        Complete the method which updates the target network with the parameters of the online network\n",
    "        Hint: use the load_state_dict method!\n",
    "        '''\n",
    "    \n",
    "        #Solution:\n",
    "        \n",
    "        self.target_network.load_state_dict(self.online_network.state_dict())\n",
    "    \n",
    "    '''\n",
    "    The following method will let the DQNAgent play the game after it has worked \n",
    "    through the number of episodes for training\n",
    "    '''\n",
    "    def play_game(self, step=1, seed=123):\n",
    "        \n",
    "        '''\n",
    "        Params:\n",
    "        step = the number of the step within the epsilon decay that is used for the epsilon value of epsilon-greedy\n",
    "        seed = seed for random number generator for reproducibility\n",
    "        '''\n",
    "        #Get the optimized strategy:\n",
    "        done = False\n",
    "        #Reinitialize the game \n",
    "        # self.env = gym.make(self.env_name, render_mode='human')\n",
    "        self.env = gym.make(self.env_name, render_mode='human')\n",
    "        #Start the game\n",
    "        state, _ = self.env.reset()\n",
    "        while not done:\n",
    "            #Pick the best action \n",
    "            action = self.choose_action(step, state, True)[0]\n",
    "            next_state, rew, terminated, truncated, _ = self.env.step(action)\n",
    "            done = terminated or truncated \n",
    "            state = next_state\n",
    "            #Pause to make it easier to watch\n",
    "            time.sleep(0.05)\n",
    "        #Close the pop-up window\n",
    "        self.env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02d62e",
   "metadata": {},
   "source": [
    "After we have created our DDQNAgent class, we can re-run the experiment from above and see if we can increase the performance! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba258ff0",
   "metadata": {},
   "source": [
    "## Hyperparameters and initialization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d691c9c",
   "metadata": {},
   "source": [
    "Since the hyperparameters are the same as before, we only need to set the new hyperparameter target_update_frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89799b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait, the experience replay buffer will be filled with random transitions\n",
      "Initialization with random transitions is done!\n"
     ]
    }
   ],
   "source": [
    "env = StorageEnv(path_to_train_data=\"../../data/train.xlsx\")\n",
    "dagent = DDQNAgent(env, device, epsilon_decay, epsilon_start, epsilon_end, discount_rate, lr, buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef28616",
   "metadata": {},
   "source": [
    "### Main loop DDQN - double deep Q network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63914e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StorageEnv(path_to_train_data=\"../../data/train.xlsx\")\n",
    "average_rewards_ddqn = training_loop(env, dagent, max_episodes, target_ = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce395b6",
   "metadata": {},
   "source": [
    "**Comments**:\n",
    "\n",
    "As you can see, implementing a target network improved the performance of the deep reinforcement learning algorithm greatly! \n",
    "\n",
    "We can also plot the results of both algorithms to see the difference even more clearly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10958adb",
   "metadata": {},
   "source": [
    "**Comment**:\n",
    "\n",
    "Here we can plot the results of the algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7b71f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average reward')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(1000*(np.arange(len(average_rewards_ddqn))+1),average_rewards_ddqn)\n",
    "plt.plot(1000*(np.arange(len(average_rewards_vanilla_dqn))+1),average_rewards_vanilla_dqn)\n",
    "# specifying horizontal line type\n",
    "plt.axhline(y = -110, color = 'r', linestyle = '-')\n",
    "plt.title('Average reward over the past 100 simulations')\n",
    "plt.xlabel('Number of simulations')\n",
    "plt.legend(['Double DQN', 'Vanilla DQN', 'Benchmark solving the game'])\n",
    "plt.ylabel('Average reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ae95e6",
   "metadata": {},
   "source": [
    "As we can see, the Double DQN performs significantly better than the vanilla DQN. The horizontal redline is the benchmark, as one considers the mountain car environment to be solved when the average reward over 100 subsequent trials is -110 ([check this link for further info](https://github.com/openai/gym/wiki/Leaderboard#mountaincar-v0))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6426925",
   "metadata": {},
   "source": [
    "You can play around the hyperparameter and see how the results change if, for example, you lower the discount rate or learning rate! Also, you can see if changing the neural network architecture, i.e. making it deeper, will lead to an increase in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da636772",
   "metadata": {},
   "source": [
    "## Reap the rewards of the hard work - see the DDQN play the game! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e8e811",
   "metadata": {},
   "source": [
    "Now that we worked through two different deep reinforcement learning architectures, we can see the DQN solve the game. The code below with let the DQNAgent play the mountain car game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afae6055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dagent.play_game()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf0672",
   "metadata": {},
   "source": [
    "## Visualize the result in a 3D plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ed3ad4",
   "metadata": {},
   "source": [
    "We can visualize the result in a 3D plot, plotting the x-position as well as the velocity with the corresponding value function. To recall, the value of a particular state is, in case of a greedy policy, the corresponding maximum state action pair! The following function will plot the value function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d14dbd",
   "metadata": {},
   "source": [
    "The following code will plot the value function that results of the DDQN algorithm in 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46794ae4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m bin_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m      5\u001b[0m bin_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(low[\u001b[38;5;241m0\u001b[39m], high[\u001b[38;5;241m0\u001b[39m], bin_size)\n\u001b[1;32m----> 6\u001b[0m bin_velocity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[43mlow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, high[\u001b[38;5;241m1\u001b[39m], bin_size)\n\u001b[0;32m      8\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(bin_x, bin_velocity)\n\u001b[0;32m      9\u001b[0m Z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(X), \u001b[38;5;28mlen\u001b[39m(Y)))\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "low = dagent.env.observation_space[0].low\n",
    "high = dagent.env.observation_space[0].high\n",
    "\n",
    "bin_size = 20\n",
    "bin_x = np.linspace(low[0], high[0], bin_size)\n",
    "bin_velocity = np.linspace(low[1], high[1], bin_size)\n",
    "\n",
    "X, Y = np.meshgrid(bin_x, bin_velocity)\n",
    "Z = np.zeros((len(X), len(Y)))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    for j in range(len(Y)):\n",
    "        Z[i][j] = dagent.return_q_value([X[0][i], Y[j][0]])\n",
    "fig = plt.figure(figsize =(10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "#ax.contour3D(X, Y, Z, 50, cmap='magma')\n",
    "ax.set_xlabel('x-position', fontsize = 18)\n",
    "ax.set_ylabel('velocity', fontsize = 18)\n",
    "ax.set_zlabel('value function', fontsize = 18)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "ax.set_title('Visualization of the value function', fontsize = 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be254b",
   "metadata": {},
   "source": [
    "**Your turn!**\n",
    "\n",
    "You can play around with the deep reinforcement learning architecture and see what impact for example the discount rate has. Also, you can modify the architecture of the neural network (by making it more deep and/or change the activation function). Just have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1214f5",
   "metadata": {},
   "source": [
    "## Extensions/Interesting notes: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9328c6",
   "metadata": {},
   "source": [
    "Following the sucess of the paper by Minh et al. (2013), research in deep reinforcement learning has progressed and a couple of extensions to the basic framework as well as tricks have been proposed, such as dueling deep Q learning (also called D3QN) and priotized experience replay. But before I give you some pointers on this, we will discuss the deadly triad in a bit more detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ba3f5",
   "metadata": {},
   "source": [
    "## 1) The deadly triad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a725339",
   "metadata": {},
   "source": [
    "Some of you might have heard of the term 'deadly triad' which refers to the instability a reinforcement learning algorithm faces, when an algorithm makes use of:\n",
    "\n",
    "- function approximation\n",
    "- bootstrapping\n",
    "- off-policy evaluation\n",
    "\n",
    "Our deep reinforcement learning algorithm makes use of all three concepts. Yet, it does **not** state that instability/divergence always occur when all three above-mentioned techniques are used. The deadly triad only states that it **can** occur. An interesting paper that addresses this issue empirically is the following paper by van Hasselt et al. (2018) [Deep Reinforcement Learning and the Deadly Triad](https://arxiv.org/pdf/1812.02648.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb749a4",
   "metadata": {},
   "source": [
    "For doing this, they realize that if one bounds the rewards in the interval between $[-1,1]$, then one can show that the corresponding Q values are bounded given by the following equation:\n",
    "\n",
    "$  \\sum_{t'=t}^{T} \\gamma^{t'-t} |r_{t'}| \\le \\sum_{t'=t}^{\\infty} \\gamma^{t'-t} |r_{t'}| \\le \\sum_{t'=t}^{\\infty} \\gamma^{t'-t} = \\frac{1}{1-\\gamma}  $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2abe3e",
   "metadata": {},
   "source": [
    "According to this, any Q-value is theoretically bounded by the above equation. In our case, by $100$ (given a discount rate of $0.99$). Hence, if the Q-value exceeds this bound, we say that soft divergence occurs.\n",
    "\n",
    "In their work, they find via running several experiments interesting insights:\n",
    "\n",
    "- If one does not correct for overestimating bias (by for example not using a target network), divergence can occur more frequently.\n",
    "\n",
    "- Increasing the multistep return decreases the chance of divergence.\n",
    "\n",
    "- The effect of the neural network size is not straightforward, as the best performing architectures in their experiment are large, but also tend to show some instabilities.\n",
    "\n",
    "Hence, they suggest that one can prevent instabilities by reducing the overestimation bias and by bootstraping on a separate network (also using multi-step returns). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd48d55",
   "metadata": {},
   "source": [
    "## 2) The importance of the random seed - instability of the DeepRL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a128340f",
   "metadata": {},
   "source": [
    "As stressed [in this good post](https://spinningup.openai.com/en/latest/spinningup/spinningup.html#closing-thoughts), the performance of DeepRL algorithms is very sensitive to stochasticity and the particular choice of the hyperparameters chosen. For this reason, one should run any DeepRL algorithm on a number of different random seeds and carefully tune the hyperparameters. This aspect is also discussed in this [paper](https://arxiv.org/pdf/1708.04133.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a8b174",
   "metadata": {},
   "source": [
    "In the following, we will show how setting different seeds affects the performance of the double deep Q network. The following code is inspired by the code [here](https://gymnasium.farama.org/tutorials/reinforce_invpend_gym_v26/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd81af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait, the experience replay buffer will be filled with random transitions\n",
      "Initialization with random transitions is done!\n",
      "----------------------------------------\n",
      "Step 9999\n",
      "Epsilon 0.05009500000000011\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 19999\n",
      "Epsilon 0.05\n",
      "Avg Rew -199.61\n",
      "\n",
      "----------------------------------------\n",
      "Step 29999\n",
      "Epsilon 0.05\n",
      "Avg Rew -199.29\n",
      "\n",
      "----------------------------------------\n",
      "Step 39999\n",
      "Epsilon 0.05\n",
      "Avg Rew -199.68\n",
      "\n",
      "----------------------------------------\n",
      "Step 49999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 59999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 69999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 79999\n",
      "Epsilon 0.05\n",
      "Avg Rew -199.78\n",
      "\n",
      "----------------------------------------\n",
      "Step 89999\n",
      "Epsilon 0.05\n",
      "Avg Rew -199.78\n",
      "\n",
      "----------------------------------------\n",
      "Step 99999\n",
      "Epsilon 0.05\n",
      "Avg Rew -196.26\n",
      "\n",
      "----------------------------------------\n",
      "Step 109999\n",
      "Epsilon 0.05\n",
      "Avg Rew -184.59\n",
      "\n",
      "----------------------------------------\n",
      "Step 119999\n",
      "Epsilon 0.05\n",
      "Avg Rew -148.22\n",
      "\n",
      "----------------------------------------\n",
      "Step 129999\n",
      "Epsilon 0.05\n",
      "Avg Rew -172.34\n",
      "\n",
      "----------------------------------------\n",
      "Step 139999\n",
      "Epsilon 0.05\n",
      "Avg Rew -198.3\n",
      "\n",
      "----------------------------------------\n",
      "Step 149999\n",
      "Epsilon 0.05\n",
      "Avg Rew -199.22\n",
      "\n",
      "----------------------------------------\n",
      "Step 159999\n",
      "Epsilon 0.05\n",
      "Avg Rew -197.32\n",
      "\n",
      "----------------------------------------\n",
      "Step 169999\n",
      "Epsilon 0.05\n",
      "Avg Rew -159.37\n",
      "\n",
      "----------------------------------------\n",
      "Step 179999\n",
      "Epsilon 0.05\n",
      "Avg Rew -149.4\n",
      "\n",
      "----------------------------------------\n",
      "Step 189999\n",
      "Epsilon 0.05\n",
      "Avg Rew -172.47\n",
      "\n",
      "----------------------------------------\n",
      "Step 199999\n",
      "Epsilon 0.05\n",
      "Avg Rew -184.2\n",
      "\n",
      "----------------------------------------\n",
      "Step 209999\n",
      "Epsilon 0.05\n",
      "Avg Rew -169.13\n",
      "\n",
      "----------------------------------------\n",
      "Step 219999\n",
      "Epsilon 0.05\n",
      "Avg Rew -156.74\n",
      "\n",
      "----------------------------------------\n",
      "Step 229999\n",
      "Epsilon 0.05\n",
      "Avg Rew -164.78\n",
      "\n",
      "----------------------------------------\n",
      "Step 239999\n",
      "Epsilon 0.05\n",
      "Avg Rew -186.81\n",
      "\n",
      "----------------------------------------\n",
      "Step 249999\n",
      "Epsilon 0.05\n",
      "Avg Rew -160.15\n",
      "\n",
      "Please wait, the experience replay buffer will be filled with random transitions\n",
      "Initialization with random transitions is done!\n",
      "----------------------------------------\n",
      "Step 9999\n",
      "Epsilon 0.05009500000000011\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 19999\n",
      "Epsilon 0.05\n",
      "Avg Rew -198.88\n",
      "\n",
      "----------------------------------------\n",
      "Step 29999\n",
      "Epsilon 0.05\n",
      "Avg Rew -198.81\n",
      "\n",
      "----------------------------------------\n",
      "Step 39999\n",
      "Epsilon 0.05\n",
      "Avg Rew -199.48\n",
      "\n",
      "----------------------------------------\n",
      "Step 49999\n",
      "Epsilon 0.05\n",
      "Avg Rew -199.55\n",
      "\n",
      "----------------------------------------\n",
      "Step 59999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 69999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 79999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 89999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 99999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 109999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 119999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n",
      "----------------------------------------\n",
      "Step 129999\n",
      "Epsilon 0.05\n",
      "Avg Rew -200.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rewards_for_different_seeds = []\n",
    "for seed in range(5): # Here we go for 5 seeds only, as otherwise the code runs for too long!\n",
    "    # Reset the pytorch and numpy seeds\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Initialize the agent:\n",
    "    dagent = DDQNAgent(env_name, device, epsilon_decay, epsilon_start, \n",
    "                       epsilon_end, discount_rate, lr, buffer_size, seed)\n",
    "    \n",
    "    rewards_for_different_seeds.append(training_loop(env_name, dagent, max_episodes, target_ = True)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd050e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create a dataframe to plot using seaborn library\n",
    "rewards = pd.DataFrame(rewards_for_different_seeds).melt()\n",
    "rewards.rename(columns={\"variable\": \"episodes\", \"value\": \"reward\"}, inplace=True)\n",
    "sns.set(style=\"darkgrid\", context=\"talk\", palette=\"rainbow\")\n",
    "sns.lineplot(x=\"episodes\", y=\"reward\", data=rewards).set(\n",
    "    title=\"Performance of Double DQN for different seeds (MountainCar-v0)\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3dfa99",
   "metadata": {},
   "source": [
    "**Comment**:\n",
    "As expected, the performance of the DDQN algrorithm is heavily affected by the different seeds! This illustrates the importance of running the experiment with different seeds!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160dd64e",
   "metadata": {},
   "source": [
    "## 3) Dynamic discount rate "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82524f2",
   "metadata": {},
   "source": [
    "One of the hyperparameter that one needs to choose carefully is the discount rate $\\gamma$. In their work, [Francois-Lavet et al. (2016)](https://arxiv.org/pdf/1512.02011.pdf) show that one can increase the performance and significantly decrease the number of learning steps required, by not only having a dynamic $\\epsilon$ rate, but also by having a discount rate that increases over time. In particular, they suggest to:\n",
    "\n",
    "$\\gamma_{k+1} = 1 - 0.98(1- \\gamma_{k}) $\n",
    "\n",
    "The start value of gamma is set to $0.9$ and it increases up to a final value of $0.99$. You could try to implement this and check its effect on the result!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22661023",
   "metadata": {},
   "source": [
    "## 4) Priotized experience replay "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a738bf",
   "metadata": {},
   "source": [
    "As we saw above, an important part of deep reinforcement learning is the experience replay buffer. This concept lets the agent remember and reuse old experiences from the past. Yet, those samples were sampled uniformly. Yet, one could imagine that some experiences are more fruitful for the agent to be replayed than others. Intuitively, one would like to replay experiences for which the agent can learn the most. To do this, one needs to change the sample procedure in a way that experiences for which the agent can learn more have a higher sampling probability. This is the key idea of the priotized experience replay buffer, as introduced by [Schaul et al. (2015)](https://arxiv.org/pdf/1511.05952.pdf). \n",
    "In their work, they propose to measure the expected learning significance by the magnitude of the temporal difference  (TD) error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e830b4",
   "metadata": {},
   "source": [
    "In particular, they propose the following. The priority of transition $p_{i}$ is based on the absolute magnitude of the TD error $\\delta_{i}$ plus a small, positive constant $\\epsilon$ which ensures that all samples have a non-zero probability to be resampled:\n",
    "\n",
    "$p_{i} = |\\delta_{i}| + \\epsilon$\n",
    "\n",
    "Then, the probability of sampling transition $i$ is defined as:\n",
    "\n",
    "$P(i) = \\frac {p_{i}^{\\alpha}}{\\sum_{k} p_{k}^{\\alpha}}$ where $\\alpha$ determines how much priotization is used (with $\\alpha = 1$ representing the standard uniform case).\n",
    "\n",
    "Given that we change the sampling procedure from a uniform one, to a different one in which transitions with a higher TD error have a higher chance of getting resampled, we need to correct for the bias that occurs as stochastic updates rely on the assumption that updates correspond to the same distribution as the expectation. This can be done via importance sampling, i.e. :\n",
    "\n",
    "$w_{i} = (\\frac {1}{N} \\frac{1}{P(i)})^{\\beta}$\n",
    "\n",
    "where $N$ refers to the size of the replay buffer and $\\beta$ to a hyperparameter (with 1 compensating fully for non-uniform probabilities). For stability reasons, they suggest to normalize the weights by dividing all weights by the corresponding largest weight in the buffer.\n",
    "\n",
    "Having this, the only change on needs to do to for the training algorithm is to multiply the gradient in the update equation with $w_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c1ff58",
   "metadata": {},
   "source": [
    "## 5) Dueling Deep Reinforcement learning - D3QN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cdf2c4",
   "metadata": {},
   "source": [
    "Another extension to the standard DDQN framework is the idea of dueling deep reinforcement learning. This was introduced by [Wang et al. (2016).](https://arxiv.org/pdf/1511.06581.pdf).\n",
    "\n",
    "The key idea is to note that the Q function can be decomposed into the value function $V(s)$ which denotes how valuable it is for an agent to be in a particular state $s$ and an advantage function $A(s,a)$ which determines how valuable it is to take a particular action $a$ in a state $s$:\n",
    "\n",
    "$Q(s,a) = V(s) + A(s,a)$\n",
    "\n",
    "Yet, given a particular Q function, one can decompose it into the components of $V(s)$ and $A(s,a)$ in many ways which  raises identifiability issues. To circumvent this issue, the authors suggest to force the highest Q value to be equal to the value function, i.e.\n",
    "\n",
    "$Q(s,a) = V(s) + ( A(s,a) - max_{a' \\in |A|}A(s,a'))$\n",
    "\n",
    "Alternatively, one can do it also using the average over all actions:\n",
    "\n",
    "\n",
    "$Q(s,a) = V(s) + A(s,a) - \\frac{1}{||a||}\\sum_{a'}A(s,a')$\n",
    "\n",
    "To implement this in PyTorch, one only needs to seperate the layers into two different streams, where one layer calculates the value function and the other one the advantage function. Lastly, one needs to then aggregate them again (and subtract the average!)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
