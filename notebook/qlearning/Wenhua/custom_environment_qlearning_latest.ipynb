{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71BhW0cK9emd",
        "outputId": "92c0813b-4c4d-4cfe-dd9a-48aee698c766"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box, MultiDiscrete, Tuple\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import gym\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "gutXaPphnXyj"
      },
      "outputs": [],
      "source": [
        "# # fix something here maybe in order to have it so that action is adjusted in step function to closest action that is allowed at 7am,\n",
        "# # and so that the action does not result in negative battery level\n",
        "\n",
        "# def get_legal_actions_at_last(all_actions, current_level, min_level=2):\n",
        "#     '''\n",
        "#     Expected behavior: [-2,-1,0,1,2], currently 0 -> [2]\n",
        "#     Expected behavior: [-2,-1,0,1,2], currently 1 -> [1,2]\n",
        "#     Expected behavior: [-2,-1,0,1,2], currently 2 -> [0,1,2]\n",
        "#     Expected behavior: [-2,-1,0,1,2], currently 3 -> [-1,0,1,2]\n",
        "#     Expected behavior: [-2,-1,0,1,2], currently 4 -> [-2,-1,0,1,2]\n",
        "#     '''\n",
        "#     all_actions = np.asarray(all_actions)\n",
        "#     charge_needed = min_level - current_level\n",
        "#     avail_actions = all_actions[np.where(all_actions >= charge_needed)]\n",
        "#     # avail_actions = all_actions[list(np.where(all_actions >= charge_needed)[0])]\n",
        "#     return avail_actions.tolist()\n",
        "\n",
        "# def get_legal_actions(all_actions, current_level, min_level=0):\n",
        "#     all_actions = np.asarray(all_actions)sim\n",
        "#     underlying_levels = all_actions + current_level\n",
        "#     # avail_actions = all_actions[list(np.where(underlying_levels >= 0)[0])]\n",
        "#     avail_actions = all_actions[np.where(underlying_levels >= min_level)]\n",
        "#     return avail_actions.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fix something here maybe in order to have it so that action is adjusted in step function to closest action that is allowed at 7am,\n",
        "# and so that the action does not result in negative battery level\n",
        "\n",
        "# def get_legal_actions_at_last(all_actions, current_level, min_level=2):\n",
        "#     '''\n",
        "#     Expected behavior: [-2,-1,0,1,2], currently 0 -> [2]\n",
        "#     Expected behavior: [-2,-1,0,1,2], currently 1 -> [1,2]\n",
        "#     Expected behavior: [-2,-1,0,1,2], currently 2 -> [0,1,2]\n",
        "#     Expected behavior: [-2,-1,0,1,2], currently 3 -> [-1,0,1,2]\n",
        "#     Expected behavior: [-2,-1,0,1,2], currently 4 -> [-2,-1,0,1,2]\n",
        "#     '''\n",
        "#     all_actions = np.asarray(all_actions)\n",
        "#     charge_needed = min_level - current_level\n",
        "#     avail_actions = all_actions[np.where(all_actions >= charge_needed)]\n",
        "#     # avail_actions = all_actions[list(np.where(all_actions >= charge_needed)[0])]\n",
        "#     return avail_actions.tolist()\n",
        "\n",
        "# def get_legal_actions(all_actions, current_level, min_level=0):\n",
        "#     all_actions = np.asarray(all_actions)\n",
        "#     underlying_levels = all_actions + current_level\n",
        "#     # avail_actions = all_actions[list(np.where(underlying_levels >= 0)[0])]\n",
        "#     avail_actions = all_actions[np.where(underlying_levels >= min_level)]\n",
        "#     return avail_actions.tolist()\n",
        "\n",
        "\n",
        "# def get_legal_range(full_range, current_level, min_level=20):\n",
        "#     '''\n",
        "#     Expected behavior: [-25,25], currently 0 -> [20,25]\n",
        "#     Expected behavior: [-25,25], currently 10 -> [10,25]\n",
        "#     Expected behavior: [-25,25], currently 20-> [0,25]\n",
        "#     Expected behavior: [-25,25], currently 30-> [-10,25]\n",
        "#     Expected behavior: [-25,25], currently 40 -> [-20,25]\n",
        "#     Expected behavior: [-25,25], currently 50 -> [-25,25]\n",
        "#     '''\n",
        "#     full_range = np.asarray(full_range)\n",
        "#     charge_needed = min_level - current_level\n",
        "#     avail_actions = [charge_needed, 25]\n",
        "#     return avail_actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "t8HtS9kPM2qG"
      },
      "outputs": [],
      "source": [
        "# # 1 make the step function go through one hour at a time, and through the entire dataframe (sequentially) in total *\n",
        "# # 2 take at_home out of the state *\n",
        "# # 3 include the action mechanics inside of the step function *\n",
        "# # 4 test environment again on random policy loop *\n",
        "# # 5 try q learning\n",
        "# # 6 change action to -1, 1 range\n",
        "# # 7 change reward calculation *\n",
        "# # 8 test with the test environment (validate using main.py)\n",
        "# # 9 include electricity price, and maybe more time elements in the state representation (week/month/year)\n",
        "# # 10 change hour from 08-07 to 01-00\n",
        "\n",
        "# #\n",
        "# # action comes in in continuous form, is modified in the step function in continuous form within range [-1,1], which\n",
        "# # is used then to update state variables, i.e. battery level, into a continuous variable between [0,50]\n",
        "# # state is returned in continuous form\n",
        "# # in tabular Q learning, state (from env.step) is taken and discretized to get next action\n",
        "# # in approximator methods, state is taken as continuous and used to get next action\n",
        "\n",
        "# class StorageEnv(Env):\n",
        "#     def __init__(self, path_to_train_data):\n",
        "#         '''\n",
        "#         Initialization of the energy storage environment;\n",
        "#         We interpret a run through all historical price data as one trajectory = one episode,\n",
        "#         where for each hour of each day, we can run the step function to update from one state\n",
        "#         to the next, given some action for that hour (the step function will return the next\n",
        "#         state, as well as next reward, and whether the entire historical dataset has been\n",
        "#         iterated through using the 'done' variable in the return statement).\n",
        "#         '''\n",
        "\n",
        "#         self.train_data = pd.read_excel(path_to_train_data)\n",
        "#         self.price_values = self.train_data.iloc[:, 1:25].to_numpy()\n",
        "#         self.timestamps = self.train_data['PRICES']\n",
        "#         self.nr_hours = self.price_values.shape[0]*self.price_values.shape[1] # number of hours in the dataset in total = 25208 for train.xlsx\n",
        "\n",
        "\n",
        "#         self.values_actions =  [-20, -10, 0, 10, 20]\n",
        "#         self.batteries =  [0, 10, 20, 30, 40, 50]\n",
        "#         self.action_repr = [-2,-1,0,1,2]\n",
        "\n",
        "#         self.done = False # indicates whether trajectory (run through entire dataset) has finished, analogous to 'terminated' argument\n",
        "\n",
        "#         self.action_space = Discrete(5, start=-2)\n",
        "#         self.battery_space = Discrete(6, start=0)\n",
        "#         self.position_space = Discrete(2, start=0)\n",
        "\n",
        "#         self.counter = 0\n",
        "#         self.hour = 1\n",
        "#         self.day = 1\n",
        "#         self.num_hours_day = 24\n",
        "\n",
        "#         self.min_battery_level_start = 20\n",
        "#         self.min_battery_level = 0\n",
        "#         self.max_battery_level = 50\n",
        "#         self.max_charging_level = 25\n",
        "\n",
        "#         # battery level from 0 to 50 (10 incr.), indication car at home or not\n",
        "#         self.observation_space = MultiDiscrete([self.battery_space.n,\n",
        "#                                                 self.position_space.n,\n",
        "#                                                 self.num_hours_day])\n",
        "\n",
        "#         # initialize state vars\n",
        "#         self.battery_level = np.random.randint(self.min_battery_level_start, self.max_battery_level)\n",
        "#         # randomly initialize athome with 50/50 chance of being away at hour 0 (8am) or not\n",
        "#         self.at_home = np.random.randint(self.position_space.n) # dont need this anymore or?\n",
        "#         # initial state\n",
        "#         self.state = [self.battery_level, self.hour]\n",
        "\n",
        "\n",
        "#     def step(self, action):\n",
        "#         ######### at current timestep t\n",
        "#         ### battery comsumption at timestep t\n",
        "\n",
        "#         # no charging/discharging if car is away, besides reduction of batter level by 20kwh at 8am (enforced later on)\n",
        "#         if not self.at_home: # check if car is currently away, enforced by overriding previous if statement\n",
        "#           action = 0\n",
        "\n",
        "#         # meeting constraints of having 20kwh at 7am, and alwys more than 0kwh stored\n",
        "#         elif self.at_home:\n",
        "#           # calculate the exact action you need to get the battery to 20kwh, by taking the min of all sufficient (=legal) actions\n",
        "#           if self.hour == 7:\n",
        "#             legal_actions = get_legal_actions_at_last(self.action_repr, self.battery_level)\n",
        "#             if action not in legal_actions: # check if action chosen by agent ensures 20kwh of battery at 7am\n",
        "#               action = min(legal_actions)\n",
        "#           # rest of the day, ensure that battery stays above 0kwh\n",
        "#           else:\n",
        "#             legal_actions = get_legal_actions(self.action_repr, self.battery_level)\n",
        "#             if action not in legal_actions:\n",
        "#               action = min(legal_actions)\n",
        "\n",
        "#         # removing 20kwh from battery when going away from home\n",
        "#         if not self.at_home:\n",
        "#           self.battery_level = self.battery_level-2 if self.hour == 0 else self.battery_level\n",
        "\n",
        "#         # update battery level based on the picked acion at timestep t\n",
        "#         if self.at_home:\n",
        "#             self.battery_level += action\n",
        "\n",
        "#         # no over-charging above 50kwh\n",
        "#         if self.battery_level >= 5:\n",
        "#             self.battery_level = 5\n",
        "\n",
        "#         # should we move the constraints not lower 0 here ??\n",
        "\n",
        "#         ######### update the state for next hour, timestep t+1\n",
        "#         # keep the hour 8 ~ 18 same, otherwise athome = True\n",
        "#         self.at_home = self.at_home if self.hour < 18 else 1\n",
        "\n",
        "#         # reward calculations\n",
        "#         # if self.day-1 == 1095:\n",
        "#         #   print(f\"self.day-1 {self.day-1} | self.hour-1 {self.hour-1}  | self.price_values[self.day-1][self.hour-1] {self.price_values[self.day-1][self.hour-1]}  \")\n",
        "#         hourly_price = self.price_values[self.day-1][self.hour-1]\n",
        "#         cost_factor = 1.0 if action < 0 else 2.0\n",
        "#         efficiency_price_factor = 0.9 if action < 0 else 1.0 # obtained electricity is impacted by 0.9 when selling\n",
        "\n",
        "#         # get amount of kwh bought during this step\n",
        "#         kwhs_charged = action * 10 # change this 10 when changing action space!!!\n",
        "#         price_of_charging = kwhs_charged * cost_factor * efficiency_price_factor * (hourly_price/1000) # go from MWh to KWh, multiply by 2 if we are buying\n",
        "#         # add reward here, based on price from table\n",
        "\n",
        "#         reward = (-1.) * price_of_charging # reward for this step, positive if selling, negative when buying\n",
        "\n",
        "#         # update counter and time variables\n",
        "#         self.counter += 1 # update continuous counter (running from 0 - len(df)*24)\n",
        "#         self.hour += 1 # increment hour (running from 1-24 and back to 1 after the day passed)\n",
        "\n",
        "#         if self.counter % 24 == 0: # check if day is over, meaning that it is midnight at timestep t+1\n",
        "#             self.hour = 1 # reset hour of the day for next timestep\n",
        "#             self.day += 1 # increment to start of next day\n",
        "\n",
        "#         # update state\n",
        "#         self.state = [self.battery_level, self.hour]\n",
        "\n",
        "#         # check if all hours in the dataset have been seen\n",
        "#         self.done = self.counter+1 == self.nr_hours\n",
        "\n",
        "#         truncated = False\n",
        "#         info = {}\n",
        "\n",
        "#         return self.state, reward, self.done, truncated, info\n",
        "\n",
        "#     def render(self):\n",
        "#         pass\n",
        "\n",
        "#     def reset(self):\n",
        "#       # initialize battery level randomly between 0 and 6, representing the space 0-50kwh\n",
        "#       self.battery_level = np.random.uniform(self.min_battery_level_start, self.max_battery_level)\n",
        "#       # randomly initialize athome with 50/50 chance of being away at hour 0 (8am) or not\n",
        "#       self.at_home = np.random.randint(self.position_space.n)\n",
        "#       # hour may not need to be in the state..?\n",
        "#       self.hour = 1\n",
        "#       self.day = 1\n",
        "#       self.counter = 0\n",
        "#       self.done = False\n",
        "#        # initial state\n",
        "#       self.state = [self.battery_level, self.hour]\n",
        "\n",
        "#       return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1 make the step function go through one hour at a time, and through the entire dataframe (sequentially) in total *\n",
        "# 2 take at_home out of the state *\n",
        "# 3 include the action mechanics inside of the step function *\n",
        "# 4 test environment again on random policy loop *\n",
        "# 5 try q learning\n",
        "# 6 change action to -1, 1 range *\n",
        "# 7 change reward calculation *\n",
        "# 8 test with the test environment (validate using main.py)\n",
        "# 9 include electricity price, and maybe more time elements in the state representation (week/month/year)\n",
        "# 10 change hour from 08-07 to 01-00 *\n",
        "\n",
        "### contuinuous action mechanism:\n",
        "# action comes in in continuous form in training loop, is modified in the step function in continuous form within range [-1,1], which\n",
        "# is used then to update state variables, i.e. battery level, into a continuous variable between [0,50]\n",
        "# state is returned in continuous form\n",
        "# in tabular Q learning, state (from env.step) is taken and discretized to get next action\n",
        "# in approximator methods, state is taken as continuous and used to get next action\n",
        "\n",
        "class StorageEnv(gym.Env):\n",
        "    def __init__(self, path_to_train_data, num_actions=3, penalty_on=True):\n",
        "        '''\n",
        "        Initialization of the energy storage environment;\n",
        "        We interpret a run through all historical price data as one trajectory = one episode,\n",
        "        where for each hour of each day, we can run the step function to update from one state\n",
        "        to the next, given some action for that hour (the step function will return the next\n",
        "        state, as well as next reward, and whether the entire historical dataset has been\n",
        "        iterated through using the 'done' variable in the return statement).\n",
        "        '''\n",
        "\n",
        "        # check if penalties are enabled or not\n",
        "        self.penalty_on = penalty_on\n",
        "\n",
        "        self.train_data = pd.read_excel(path_to_train_data)\n",
        "        self.price_values = self.train_data.iloc[:, 1:25].to_numpy()\n",
        "        self.timestamps = self.train_data['PRICES']\n",
        "        self.state = np.empty(3)\n",
        "        # self.nr_hours = self.price_values.shape[0]*self.price_values.shape[1] # number of hours in the dataset in total = 25208 for train.xlsx\n",
        "        self.nr_hours = np.size(self.price_values)\n",
        "        # print(self.nr_hours)\n",
        "\n",
        "        self.battery_range = Box(low=0, high=50, shape=(1,), dtype=np.float32)\n",
        "        # print(self.price_values.max())\n",
        "        self.price_range = Box(low=0, high=self.price_values.max(), shape=(1,), dtype=np.float32)\n",
        "        # self.hour_range = Discrete(24, start=1)\n",
        "\n",
        "        # obv space: battery level from 0 to 50 (continuous), hour of the dayt\n",
        "        # self.observation_space = Tuple((self.battery_range, self.hour_range))\n",
        "        self.position_range = Discrete(2)\n",
        "        # self.dow_range = Discrete(7)\n",
        "        # self.month_range = Discrete(12, start=1)\n",
        "        # obv space: battery level from 0 to 50 (continuous), hour of the dayt\n",
        "        # self.observation_space = Tuple((self.battery_range, self.price_range, self.hour_range ))\n",
        "\n",
        "        # self.action_space = np.array([i for i in range(21)]) / 10.0 - 1.0\n",
        "        self.action_spaces = {\n",
        "            '3': np.array([-1, 0, 1]),\n",
        "            '5': np.array([-1, -0.5, 0, 0.5, 1]),\n",
        "            '11': np.array([-1.0, -0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1.0 ]),\n",
        "            '21': np.array([-1.0, -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1,  0 , 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1.0 ])\n",
        "        }\n",
        "        self.action_space = self.action_spaces[str(int(num_actions))]\n",
        "\n",
        "        # print(self.action_space)\n",
        "        # self.actions = Discrete(len(self.action_repr))\n",
        "        self.action_space_n = len(self.action_space)\n",
        "        print(f\"Action space ({self.action_space_n} actions): {self.action_space}\")\n",
        "        # self.action_space = Discrete(21, start=-2) # -1 -0.9 8 7 6 5 4 3 2 1 0 1 2 \n",
        "        # self.cont_action_space = Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
        "        # self.action_repr = [-2,-1,0,1,2]\n",
        "\n",
        "        # self.position_space = Discrete(2, start=0)\n",
        "\n",
        "        # self.done = False # indicates whether trajectory (run through entire dataset) has finished, analogous to 'terminated' argument\n",
        "        \n",
        "        # self.min_battery_level_start = 20  #minimum_morning_level\n",
        "        # self.min_battery_level = 0\n",
        "        # self.max_battery_level = 50   #battery_capacity\n",
        "        # self.max_charging_level = 25\n",
        "        \n",
        "        # Battery characteristics\n",
        "        self.battery_capacity = 50  # kWh\n",
        "        self.max_power = 25 / 0.9  # kW\n",
        "        self.charge_efficiency = 0.9  # -\n",
        "        self.discharge_efficiency = 0.9  # -\n",
        "        # self.battery_level = self.battery_capacity / 2  # kWh (start at 50%)\n",
        "        self.minimum_morning_level = 20  # kWh\n",
        "        self.car_use_consumption = 20  # kWh\n",
        "\n",
        "        # Time Tracking\n",
        "        # self.counter = 0\n",
        "        # self.hour = 1\n",
        "        # self.day = 1\n",
        "        # self.car_is_available = True\n",
        "\n",
        "        # initialize state vars\n",
        "        # self.battery_level = np.random.uniform(self.min_battery_level_start, self.max_battery_level) # continuous value between 20 and 50\n",
        "        # randomly initialize athome with 50/50 chance of being away at hour 0 (8am) or not\n",
        "        # self.at_home = np.random.randint(self.position_space.n) # 50% chance at home at start of each day\n",
        "        # initial state\n",
        "        # self.state = np.array([self.battery_level, self.hour])\n",
        "\n",
        "\n",
        "    def step(self, action): # action is between -1 and 1\n",
        "        action = np.squeeze(action)\n",
        "        # print(action)\n",
        "        ######### at current timestep t\n",
        "        ### battery comsumption at timestep t\n",
        "        \n",
        "        if action <-1 or action >1:\n",
        "            raise ValueError('Action must be between -1 and 1')\n",
        "        \n",
        "        # store the action into action_bs\n",
        "        action_bs = action\n",
        "        # Calculate if, at 7am and after the chosen action, the battery level will be below the minimum morning level:\n",
        "        penalty = 0.0 # peality\n",
        "        if self.hour == 7:\n",
        "            if action > 0 and (self.battery_level < self.minimum_morning_level):\n",
        "                if (\n",
        "                        self.battery_level + action * self.max_power * self.charge_efficiency) < self.minimum_morning_level:  # If the chosen action will not charge the battery to 20kWh\n",
        "                    action = (self.minimum_morning_level - self.battery_level) / (\n",
        "                                self.max_power * self.charge_efficiency)  # Charge until 20kWh\n",
        "                    # charge higher to nearest legal action\n",
        "                    # action = math.ceil(action * 10.0) / 10.0\n",
        "\n",
        "            elif action < 0:\n",
        "                if (self.battery_level + action * self.max_power) < self.minimum_morning_level:\n",
        "                    if self.battery_level < self.minimum_morning_level:  # If the level was lower than 20kWh, charge until 20kWh\n",
        "                        action = (self.minimum_morning_level - self.battery_level) / (\n",
        "                                    self.max_power * self.charge_efficiency)  # Charge until 20kWh\n",
        "                        # charge higher to nearest legal action\n",
        "                        # action = math.ceil(action * 10.0) / 10.0\n",
        "                    elif self.battery_level >= self.minimum_morning_level:  # If the level was higher than 20kWh, discharge until 20kWh\n",
        "                        action = (self.minimum_morning_level - self.battery_level) / (\n",
        "                            self.max_power)  # Discharge until 20kWh\n",
        "                        # discharge less to keep higher than 20kwh\n",
        "                        # action = math.ceil(action * 10.0) / 10.0\n",
        "            elif action == 0:\n",
        "                if self.battery_level < self.minimum_morning_level:\n",
        "                    action = (self.minimum_morning_level - self.battery_level) / (\n",
        "                                self.max_power * self.charge_efficiency)\n",
        "                    # charge higher to nearest legal action\n",
        "                    # action = math.ceil(action * 10.0) / 10.0\n",
        "                    \n",
        "        if abs(action_bs - action) != 0:   \n",
        "            #* np.exp(abs(action_bs - action))\n",
        "            penalty += 1000.0 if self.penalty_on else 0.\n",
        "\n",
        "        # if it is 8am, decide whether car will go away or stay (by random chance)\n",
        "        if self.hour == 8:\n",
        "            # self.car_is_available = np.random.choice([True, False])\n",
        "            if not self.car_is_available:\n",
        "                self.battery_level -= self.car_use_consumption\n",
        "                \n",
        "        # if self.hour == 18:\n",
        "        #     self.car_is_available = True\n",
        "            \n",
        "        # convert action [-1,1] to actual kwh charging (transform to [-25,25])\n",
        "        # if action > 0:\n",
        "        #   action = action * self.max_power * self.charge_efficiency\n",
        "        # # action = action * self.max_charging_level # now action lies in [-25,25]\n",
        "        # else:\n",
        "        #   action = action * self.max_power\n",
        "\n",
        "        # no charging/discharging if car is away, besides reduction of batter level by 20kwh at 8am (enforced later on)\n",
        "        if not self.car_is_available: # check if car is currently away, enforced by overriding previous if statement\n",
        "            action = 0\n",
        "            if abs(action_bs - action) != 0:   \n",
        "                #* np.exp(abs(action_bs - action))\n",
        "                penalty += 1000.0 if self.penalty_on else 0.\n",
        "\n",
        "\n",
        "        # Calculate the costs and battery level when charging (action >0)\n",
        "        if (action > 0) and (self.battery_level <= self.battery_capacity):\n",
        "            if (self.battery_level + action * self.max_power * self.charge_efficiency) > self.battery_capacity:\n",
        "                action = (self.battery_capacity - self.battery_level) / (self.max_power * self.charge_efficiency)\n",
        "                # charge less to nearest legal action\n",
        "                # action = math.floor(action * 10.0) / 10.0\n",
        "            charged_electricity_kW = action * self.max_power\n",
        "            charged_electricity_costs = charged_electricity_kW * self.price_values[self.day - 1][\n",
        "                self.hour - 1] * 2 * 1e-3\n",
        "            if abs(action_bs - action) != 0:\n",
        "                penalty += 1000.0 if self.penalty_on else 0.\n",
        "            reward = -charged_electricity_costs - penalty\n",
        "            self.battery_level += charged_electricity_kW * self.charge_efficiency\n",
        "\n",
        "        # Calculate the profits and battery level when discharging (action <0)\n",
        "        elif (action < 0) and (self.battery_level >= 0):\n",
        "            if (self.battery_level + action * self.max_power) < 0:\n",
        "                action = -self.battery_level / (self.max_power)\n",
        "                # discharge less to nearest legal action\n",
        "                # action = math.ceil(action * 10.0) / 10.0\n",
        "            if abs(action_bs - action) != 0:\n",
        "                penalty += 1000.0 if self.penalty_on else 0\n",
        "                \n",
        "            discharged_electricity_kWh = action * self.max_power  # Negative discharge value\n",
        "            discharged_electricity_profits = abs(discharged_electricity_kWh) * self.discharge_efficiency * \\\n",
        "                                             self.price_values[self.day - 1][self.hour - 1] * 1e-3\n",
        "                                             \n",
        "            reward = discharged_electricity_profits - penalty\n",
        "            self.battery_level += discharged_electricity_kWh\n",
        "            # Some small numerical errors causing the battery level to be 1e-14 to 1e-17 under 0 :\n",
        "            if self.battery_level < 0:\n",
        "                self.battery_level = 0\n",
        "\n",
        "        else:\n",
        "            reward = 0.\n",
        "            \n",
        "\n",
        "        # # meeting constraints of having 20kwh at 7am, and alwys more than 0kwh stored\n",
        "        # if self.car_is_available:\n",
        "        #   low = self.cont_action_space.low[0]\n",
        "        #   high = self.cont_action_space.high[0]\n",
        "        #   # calculate the exact action you need to get the battery to 20kwh, by taking the min of all sufficient (=legal) actions\n",
        "        #   if self.hour == 7: # adapt legal action calculating functions\n",
        "        #     legal_actions = get_legal_range([low, high], self.battery_level, min_level = 20)\n",
        "        #     if not (legal_actions[0] <= action <= legal_actions[1]): # check if action chosen by agent ensures 20kwh of battery at 7am\n",
        "        #       action = legal_actions[0] # charge needed for 20kwh, if initial action would result in <20 charge\n",
        "        #   # rest of the day, ensure that battery stays above or at 0kwh\n",
        "        #   else:\n",
        "        #     legal_actions = get_legal_range([self.cont_action_space.low[0], self.cont_action_space.high[0]], self.battery_level, min_level=0)\n",
        "        #     if not (legal_actions[0] <= action <= legal_actions[1]): # check if action chosen by agent ensures >=0kwh of battery at 7am\n",
        "        #       action = legal_actions[0] # charge needed to have positive >=0kwh charge, if initial action would result in negative <0kwh\n",
        "\n",
        "        # removing 20kwh from battery when going away from home\n",
        "        # if not self.car_is_available:\n",
        "        #   self.battery_level = self.battery_level - 20 if self.hour == 8 else self.battery_level\n",
        "\n",
        "        # update battery level based on the picked acion at timestep t\n",
        "        # if self.car_is_available:\n",
        "        #     self.battery_level += action\n",
        "\n",
        "        # no over-charging above 50kwh\n",
        "        # if self.battery_level >= 50:\n",
        "        #     self.battery_level = 50\n",
        "\n",
        "        # should we move the constraints not lower 0 here ??\n",
        "\n",
        "        ######### update the state for next hour, timestep t+1\n",
        "        # keep the hour 8 ~ 18 same, otherwise athome = True\n",
        "        # self.car_is_available = self.car_is_available if 8 <= self.hour < 18 else 1 # TO-DO: check if this should not be <= 18 instead\n",
        "\n",
        "        # reward calculations\n",
        "        # hourly_price = self.price_values[self.day-1][self.hour-1]\n",
        "        # cost_factor = 1.0 if action < 0 else 2.0\n",
        "        # efficiency_price_factor = 0.9 if action < 0 else 1.0 # obtained electricity is impacted by 0.9 when selling\n",
        "\n",
        "        # get amount of kwh bought during this step\n",
        "        # kwhs_charged = action # just for reading clarity\n",
        "        # price_of_charging = kwhs_charged * cost_factor * efficiency_price_factor * (hourly_price/1000) # go from MWh to KWh, multiply by 2 if we are buying\n",
        "        # # reward, based on current price from table\n",
        "        # reward = (-1.) * price_of_charging # reward for this step, positive if selling, negative when buying\n",
        "\n",
        "        # update counter and time variables\n",
        "        self.counter += 1 # update continuous counter (running from 0 - len(df)*24)\n",
        "        self.hour += 1 # increment hour (running from 1-24 and back to 1 after the day passed)\n",
        "\n",
        "        if self.counter % 24 == 0: # check if day is over, meaning that it is midnight at timestep t+1\n",
        "            self.hour = 1 # reset hour of the day for next timestep\n",
        "            self.day += 1 # increment to start of next day\n",
        "             \n",
        "        if self.hour == 8:\n",
        "            self.car_is_available = np.random.choice([True, False])\n",
        "    \n",
        "        if self.hour == 18:\n",
        "            self.car_is_available = True\n",
        "\n",
        "        # update state\n",
        "        self.state = self.observation()\n",
        "\n",
        "\n",
        "        # check if all hours in the dataset have been seen\n",
        "        # self.done = self.counter == self.nr_hours - 1\n",
        "        terminated = self.counter == self.nr_hours - 1\n",
        "        truncated = False\n",
        "        \n",
        "        info = action\n",
        "\n",
        "        return self.state, reward, terminated, truncated, info\n",
        "\n",
        "    def render(self):\n",
        "        pass\n",
        "      \n",
        "    def observation(self):  # Returns the current state\n",
        "        battery_level = self.battery_level\n",
        "        price = self.price_values[self.day - 1][self.hour - 1]\n",
        "        # print(price.max(), price.min())\n",
        "        hour = self.hour\n",
        "        day_of_week = self.timestamps[self.day - 1].dayofweek  # Monday = 0, Sunday = 6\n",
        "        day_of_year = self.timestamps[self.day - 1].dayofyear  # January 1st = 1, December 31st = 365\n",
        "        month = self.timestamps[self.day - 1].month  # January = 1, December = 12\n",
        "        year = self.timestamps[self.day - 1].year\n",
        "        self.state = np.array([\n",
        "              battery_level, \n",
        "              price, \n",
        "              int(hour), \n",
        "            #   int(self.car_is_available),\n",
        "            #   int(day_of_week), \n",
        "              #int(day_of_year), \n",
        "            #   int(month), \n",
        "              #int(year),\n",
        "             ])\n",
        "        # if match  \n",
        "        # print(self.state)\n",
        "        # print(f\"{self.timestamps[self.day - 1]} --   {day_of_week}\")\n",
        "        return self.state\n",
        "\n",
        "    def reset(self):\n",
        "      self.done = False # indicates whether trajectory (run through entire dataset) has finished, analogous to 'terminated' argument\n",
        "      self.counter = 0\n",
        "      self.hour = 1\n",
        "      self.day = 1\n",
        "      # self.car_is_available = True\n",
        "      # self.at_home = self.car_is_available  \n",
        "\n",
        "        # resetting battery charge state var, random re-initialization between 0 and 50kwh\n",
        "        #   if self.hour == 8:\n",
        "        #     self.battery_level = np.random.uniform(self.minimum_morning_level, self.battery_capacity) # continuous value between 20 and 50\n",
        "        #   elif 8 < self.hour <= 18:\n",
        "        #     self.battery_level = np.random.uniform(0, self.battery_capacity-self.minimum_morning_level) # continuous value between 20 and 50\n",
        "        #   else:\n",
        "      self.battery_level = np.random.uniform(0, self.battery_capacity) # continuous value between 0 and 50\n",
        "        \n",
        "      # randomly re-initialize athome with 50/50 chance of being away at hour 0 (8am) or not\n",
        "\n",
        "      self.car_is_available = True  # np.random.randint(self.position_space.n) # 50% chance at home at start of each day\n",
        "      # new initial state\n",
        "      self.state = self.observation()\n",
        "    #   self.state = np.array([self.battery_level, self.hour])\n",
        "\n",
        "      return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "class QAgent():\n",
        "    \n",
        "    def __init__(self, env, bin_size = {'battery': 6, 'price': 3,'hour': 3, 'action': 3},\n",
        "                  properties = {'reward_shaping':True, 'penalties':True, 'nr_simulations':10, 'discount_rate':0.95}):\n",
        "        \n",
        "        '''\n",
        "        Params:\n",
        "        \n",
        "        env_name = name of the specific environment that the agent wants to solve\n",
        "        discount_rate = discount rate used for future rewards\n",
        "        bin_size = number of bins used for discretizing the state space\n",
        "        \n",
        "        '''\n",
        "        \n",
        "        #create an environment\n",
        "        self.env = env\n",
        "        \n",
        "        # get all agent properties\n",
        "        self.properties = properties\n",
        "        self.discount_rate = self.properties['discount_rate']\n",
        "        self.properties_path = f\"disc_{self.properties['discount_rate']}_shap_{self.properties['reward_shaping']}_pen_{self.properties['penalties']}_sims_{self.properties['nr_simulations']}\"\n",
        "\n",
        "        # get all the bin sizes\n",
        "        self.bin_size = bin_size\n",
        "        \n",
        "        #The algorithm has then 3 different actions\n",
        "        #0: Accelerate to the left\n",
        "        #1: Don't accelerate\n",
        "        #2: Accelerate to the right\n",
        "        # self.action_space = self.env.action_space.n\n",
        "        \n",
        "\n",
        "        # self.action_repr = self.env.action_space\n",
        "        # self.actions = Discrete(len(self.action_repr))\n",
        "        self.action_space = self.env.action_space_n\n",
        "        values_price = self.env.price_values.flatten()\n",
        "        self.bin_prices = {\n",
        "            '3': np.quantile(values_price, [0, 0.5, 0.99]),\n",
        "            '4': np.quantile(values_price, [0, 0.33, 0.66, 0.99]),\n",
        "            '5': np.quantile(values_price, [0, 0.25, 0.5, 0.75, 0.99]),\n",
        "            '7': np.quantile(values_price, [0, 0.2, 0.4, 0.6, 0.7, 0.8, 0.99]),\n",
        "            '11': np.quantile(values_price, [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]),   \n",
        "        }\n",
        "\n",
        "        # self.bin_hours = {\n",
        "        #     '3': np.quantile(values_price, [0, 0.5, 1]),\n",
        "        #     '5': np.quantile(values_price, [0, 0.25, 0.5, 0.75, 1]),\n",
        "        #     '7': np.quantile(values_price, [0, 0.2, 0.4, 0.6, 0.7, 0.8, 1]),\n",
        "        #     '11': np.quantile(values_price, [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]),   \n",
        "        # }\n",
        "        \n",
        "        # print(self.action_space, self.bin_size)\n",
        "        \n",
        "        #State incorporates the observation state\n",
        "        #State[0] is x position\n",
        "        #State[1] is velocity\n",
        "    \n",
        "        #Get the low and high values of the environment space\n",
        "        # self.low = self.env.observation_space.low\n",
        "        # self.high = self.env.observation_space.high\n",
        "        \n",
        "        \n",
        "        self.battery_low = self.env.battery_range.low[0]\n",
        "        self.battery_high = self.env.battery_range.high[0]\n",
        "        self.hour_low = 0\n",
        "        self.hour_high = 24\n",
        "        \n",
        "        #Create bins for both observation features\n",
        "        self.bin_battery = np.linspace(self.battery_low, self.battery_high, self.bin_size['battery'])\n",
        "        print(f\"Battery Levels ({self.bin_size['battery']} bins): {self.bin_battery}\")\n",
        "        # 0.01\n",
        "        # confidence interval 99%\n",
        "        # print(np.quantile(values_price, 0.99))\n",
        "        # print(str(self.bin_size['price']))\n",
        "        # print(self.bin_prices[str(self.bin_size['price'])])\n",
        "        # self.bin_price = np.linspace(0, np.quantile(values_price, 0.99), self.bin_prices[str(self.bin_size['price'])])\n",
        "        # self.bin_price = np.concatenate((np.array([0]), self.bin_prices[str(self.bin_size['price'])][1:]))\n",
        "        self.bin_price = self.bin_prices[str(self.bin_size['price'])]\n",
        "        print(f\"Prices ({str(self.bin_size['price'])} bins): {self.bin_price}\")\n",
        "        \n",
        "        self.bin_hour = np.linspace(self.hour_low, self.hour_high, self.bin_size['hour'] + 1)\n",
        "        print(f\"Hours ({self.bin_size['hour']} bins): {self.bin_hour}\")\n",
        "        '''\n",
        "        ToDo:\n",
        "        \n",
        "        Please create the bins for the velocity feature in the same manner and call this variable self.bin_velocity!\n",
        "        '''\n",
        "        \n",
        "        #Solution\n",
        "        # self.bin_hour = np.linspace(self.hour_low, self.hour_high, self.bin_size['hour']) \n",
        "        \n",
        "        #Append the two bins\n",
        "        self.bins = [self.bin_battery, self.bin_price, self.bin_hour]\n",
        "        \n",
        "        self.total_output = {}\n",
        "        \n",
        "    \n",
        "    def get_shaping_reward(self, state, next_state):\n",
        "        battery_level, electricity_price, hour = state[0], state[1], state[2]\n",
        "        next_battery_level, next_electricity_price, next_hour = next_state[0], next_state[1], next_state[2]\n",
        "\n",
        "        extra_reward = 0.0\n",
        "        weight = 100.0   \n",
        "         \n",
        "        if next_battery_level < battery_level: # sell\n",
        "            extra_reward = (electricity_price - 2 * next_electricity_price) * (battery_level - next_battery_level)\n",
        "        if next_battery_level > battery_level: # buy\n",
        "            extra_reward = (2 * electricity_price - next_electricity_price) * (battery_level - next_battery_level)\n",
        "        \n",
        "        return weight * extra_reward\n",
        "    \n",
        "    def discretize_state(self, state):\n",
        "        \n",
        "        '''\n",
        "        Params:\n",
        "        state = state observation that needs to be discretized\n",
        "        \n",
        "        \n",
        "        Returns:\n",
        "        discretized state\n",
        "        '''\n",
        "        #Now we can make use of the function np.digitize and bin it\n",
        "        self.state = state\n",
        "        # print(f\"self.state: {self.state}\")\n",
        "        \n",
        "        #Create an empty state\n",
        "        digitized_state = []\n",
        "    \n",
        "        # (-inf, 0) [0, 1)    [50, )  # 52 states\n",
        "        digitized_state.append(np.digitize(self.state[0], self.bins[0], right=False) -1) \n",
        "        digitized_state.append(np.digitize(self.state[1], self.bins[1], right=False) -1)\n",
        "        digitized_state.append(np.digitize(self.state[2], self.bins[2], right=True) -1)\n",
        "        \n",
        "\n",
        "        #Returns the discretized state from an observation\n",
        "        return digitized_state\n",
        "    \n",
        "    \n",
        "    def create_Q_table(self):\n",
        "        # self.state_space = self.bin_size - 1\n",
        "        #Initialize all values in the Q-table to zero\n",
        "        self.state_battery_space = self.bin_size['battery']\n",
        "        self.state_hour_space = self.bin_size['hour']\n",
        "        self.state_price_space = self.bin_size['price']\n",
        "\n",
        "        '''\n",
        "        ToDo:\n",
        "        Initialize a zero matrix of dimension state_space * state_space * action_space and call it self.Qtable!\n",
        "        '''\n",
        "        \n",
        "        #Solution:\n",
        "        # self.Qtable = np.zeros((self.state_space, self.state_space, self.action_space))\n",
        "        self.Qtable = np.zeros((self.state_battery_space, \n",
        "                                self.state_price_space,\n",
        "                                self.state_hour_space,\n",
        "                                self.action_space))\n",
        "        # print(self.Qtable.shape)\n",
        "        \n",
        "    def save_Q_table(self):\n",
        "        table_shape = self.Qtable.shape\n",
        "        \n",
        "        num_battery_levels = table_shape[0]\n",
        "        num_price_levels = table_shape[1]\n",
        "        num_hours = table_shape[2]\n",
        "        num_actions = table_shape[3]\n",
        "        \n",
        "        filename = f\"qtable_{self.properties_path}_batt_{num_battery_levels}_price_{num_price_levels}_hour_{num_hours}_action_{num_actions}.npy\"\n",
        "        self.k = filename\n",
        "        np.save(f\"../../../data/{filename}\", self.Qtable)\n",
        "        print(f\"{filename} is saved ...\")\n",
        "        \n",
        "    def load_Q_table(self):\n",
        "        filename = f\"qtable_{self.properties_path}_batt_{self.bin_size['battery']}_price_{self.bin_size['price']}_hour_{self.bin_size['hour']}_action_{self.bin_size['action']}.npy\"\n",
        "        qtable = np.load(f\"../../../data/{filename}\")\n",
        "        return qtable\n",
        "\n",
        "    def train(self, learning_rate, epsilon = 0.05, epsilon_decay = 200, adaptive_epsilon = False, \n",
        "              adapting_learning_rate = False):\n",
        "        \n",
        "        '''\n",
        "        Params:\n",
        "        \n",
        "        simulations = number of episodes of a game to run\n",
        "        learning_rate = learning rate for the update equation\n",
        "        epsilon = epsilon value for epsilon-greedy algorithm\n",
        "        epsilon_decay = number of full episodes (games) over which the epsilon value will decay to its final value\n",
        "        adaptive_epsilon = boolean that indicates if the epsilon rate will decay over time or not\n",
        "        adapting_learning_rate = boolean that indicates if the learning rate should be adaptive or not\n",
        "        \n",
        "        '''\n",
        "        \n",
        "        #Initialize variables that keep track of the rewards\n",
        "        self.rewards = []\n",
        "        self.average_rewards = []\n",
        "        self.num_simulations = []\n",
        "        \n",
        "        #Call the Q table function to create an initialized Q table\n",
        "        self.create_Q_table()\n",
        "        \n",
        "        #Set epsilon rate, epsilon decay and learning rate\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        #Set start epsilon, so here we want a starting exploration rate of 1\n",
        "        self.epsilon_start = 1\n",
        "        self.epsilon_end = 0.05\n",
        "        \n",
        "        #If we choose adaptive learning rate, we start with a value of 1 and decay it over time!\n",
        "        if adapting_learning_rate:\n",
        "            self.learning_rate = 1\n",
        "        \n",
        "        for i in range(self.properties['nr_simulations']):\n",
        "            # initialize output for current simulation\n",
        "            self.total_output[i] = {'rewards': [], 'actions': [], 'battery_levels': []}\n",
        "            \n",
        "            if i % 10 == 0:\n",
        "                print(f'Please wait, the algorithm is learning! The current simulation is {i}')\n",
        "            # print(f'Please wait, the algorithm is learning! The current simulation is {i}')           \n",
        "            #Initialize the state\n",
        "            # state = self.env.reset()[0]   # reset returns a dict, need to take the 0th entry.\n",
        "            state = self.env.reset()\n",
        "        \n",
        "            #Set a variable that flags if an episode has terminated\n",
        "            done = False\n",
        "        \n",
        "            #Discretize the state space\n",
        "            # continous_state = state\n",
        "            state = self.discretize_state(state)\n",
        "            \n",
        "            \n",
        "            #Set the rewards to 0\n",
        "            total_rewards = 0\n",
        "            \n",
        "            #If adaptive epsilon rate\n",
        "\n",
        "            # epsilon = 0.05\n",
        "            # epsilon_decay = 1000\n",
        "            \n",
        "            # self.epsilon_start = 1\n",
        "            # self.epsilon_end = 0.05\n",
        "            if adaptive_epsilon:\n",
        "                self.epsilon = np.interp(i, [0, self.epsilon_decay], [self.epsilon_start, self.epsilon_end])\n",
        "                \n",
        "                #Logging just to check it decays as we want it to do, we just print out the first three statements\n",
        "                if i % 5 == 0 and i <= 100:\n",
        "                    print(f\"The current epsilon rate is {self.epsilon}\")\n",
        "                \n",
        "            #Loop until an episode has terminated\n",
        "            while not done:\n",
        "                \n",
        "                #Pick an action based on epsilon greedy\n",
        "                \n",
        "                '''\n",
        "                ToDo: Write the if statement that picks a random action\n",
        "                Tip: Make use of np.random.uniform() and the self.epsilon to make a decision!\n",
        "                Tip: You can also make use of the method sample() of the self.env.action_space \n",
        "                    to generate a random action!\n",
        "                '''\n",
        "                \n",
        "                #Solution:\n",
        "                \n",
        "                #Pick random action\n",
        "                if np.random.uniform(0, 1) > 1-self.epsilon:\n",
        "                    #This picks a random action from 0,1,2\n",
        "                    # action = self.env.action_space.sample()\n",
        "                    action = np.random.choice(self.env.action_space)\n",
        "                    action_i = np.where(self.env.action_space == action)[0][0]   \n",
        "                #Pick a greedy action\n",
        "                else:\n",
        "                    action_i = np.argmax(self.Qtable[state[0],\n",
        "                                                     state[1],\n",
        "                                                     state[2],\n",
        "                                                     :])\n",
        "                    action = self.env.action_space[action_i]\n",
        "\n",
        "                # Correct small numerical errors :  \n",
        "                action = round(action, 3)\n",
        "                    \n",
        "                #Now sample the next_state, reward, done and info from the environment\n",
        "                \n",
        "                next_state, reward, terminated, truncated, info = self.env.step(action)\n",
        "                done =  terminated or truncated\n",
        "                \n",
        "\n",
        "                # continous_next_state = next_state\n",
        "                next_state = self.discretize_state(next_state)\n",
        "                # print(next_state)\n",
        "                #Target value \n",
        "\n",
        "                Q_target = (reward + self.discount_rate*np.max(self.Qtable[next_state[0], \n",
        "                                                                           next_state[1],\n",
        "                                                                           next_state[2],\n",
        "                                                                           ]))\n",
        "                \n",
        "                # enable/disable reward shaping\n",
        "                if self.properties[\"reward_shaping\"]:\n",
        "                    Q_target += self.get_shaping_reward(state, next_state)\n",
        "                \n",
        "                #Calculate the Temporal difference error (delta)\n",
        "                delta = self.learning_rate * (Q_target - self.Qtable[state[0], \n",
        "                                                                     state[1], \n",
        "                                                                     state[2],     \n",
        "                                                                     action_i])\n",
        "                \n",
        "                #Update the Q-value\n",
        "                self.Qtable[state[0], \n",
        "                            state[1], \n",
        "                            state[2], \n",
        "                            action_i] = self.Qtable[state[0], \n",
        "                                                    state[1], \n",
        "                                                    state[2], \n",
        "                                                    action_i] + delta\n",
        "                \n",
        "                # update the reward and the hyperparameters\n",
        "                # and transform from numpy dtypes to native python types if necessary (to allow JSON encoding) \n",
        "\n",
        "                # print('reward', reward, type(reward))\n",
        "                # print('action', action, type(action))\n",
        "                # print('battery', state[0], type(state[0]))\n",
        "                self.total_output[i]['rewards'] += [float(reward)] if not isinstance(reward,float) else [reward]\n",
        "                self.total_output[i]['actions'] += [float(action)] if not isinstance(action,float) else [action]\n",
        "                self.total_output[i]['battery_levels'] += [int(state[0])] if not isinstance(state[0],int) else [state[0]]\n",
        "                \n",
        "                total_rewards += reward\n",
        "\n",
        "                # update state to next state\n",
        "                state = next_state\n",
        "                \n",
        "                \n",
        "            \n",
        "            if adapting_learning_rate:\n",
        "                self.learning_rate = self.learning_rate/np.sqrt(i+1)\n",
        "            \n",
        "            self.rewards.append(total_rewards)\n",
        "            \n",
        "            #Calculate the average score over 100 episodes\n",
        "            if i % 10 == 0:\n",
        "                self.average_rewards.append(np.mean(self.rewards))\n",
        "                self.num_simulations.append(i+1)\n",
        "                \n",
        "                #Initialize a new reward list, as otherwise the average values would reflect all rewards!\n",
        "                self.rewards = []\n",
        "        \n",
        "        print('The simulation is done!')\n",
        "        \n",
        "\n",
        "        \n",
        "    def visualize_rewards(self):\n",
        "        plt.figure(figsize =(7.5,7.5))\n",
        "        plt.plot(self.num_simulations, self.average_rewards)\n",
        "        # plt.axhline(y = -110, color = 'r', linestyle = '-')\n",
        "        plt.title('Average reward over the past 10 simulations', fontsize = 10)\n",
        "        # plt.legend(['Q-learning performance','Benchmark'])\n",
        "        plt.xlabel('Number of simulations', fontsize = 10)\n",
        "        plt.ylabel('Average reward', fontsize = 10)\n",
        "            \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action space (3 actions): [-1  0  1]\n",
            "{'battery': 6, 'price': 3, 'hour': 3, 'action': 3}\n",
            "{'reward_shaping': 0, 'penalties': 0, 'nr_simulations': 400, 'discount_rate': 0.95}\n",
            "Battery Levels (6 bins): [ 0. 10. 20. 30. 40. 50.]\n",
            "Prices (3 bins): [1.0e-02 4.3e+01 1.5e+02]\n",
            "Hours (3 bins): [ 0.  8. 16. 24.]\n",
            "Please wait, the algorithm is learning! The current simulation is 0\n",
            "The current epsilon rate is 1.0\n",
            "The current epsilon rate is 0.97625\n",
            "Please wait, the algorithm is learning! The current simulation is 10\n",
            "The current epsilon rate is 0.9525\n",
            "The current epsilon rate is 0.92875\n",
            "Please wait, the algorithm is learning! The current simulation is 20\n",
            "The current epsilon rate is 0.905\n",
            "The current epsilon rate is 0.88125\n",
            "Please wait, the algorithm is learning! The current simulation is 30\n",
            "The current epsilon rate is 0.8575\n",
            "The current epsilon rate is 0.83375\n",
            "Please wait, the algorithm is learning! The current simulation is 40\n",
            "The current epsilon rate is 0.81\n",
            "The current epsilon rate is 0.78625\n",
            "Please wait, the algorithm is learning! The current simulation is 50\n",
            "The current epsilon rate is 0.7625\n",
            "The current epsilon rate is 0.73875\n",
            "Please wait, the algorithm is learning! The current simulation is 60\n",
            "The current epsilon rate is 0.7150000000000001\n",
            "The current epsilon rate is 0.69125\n",
            "Please wait, the algorithm is learning! The current simulation is 70\n",
            "The current epsilon rate is 0.6675\n",
            "The current epsilon rate is 0.64375\n",
            "Please wait, the algorithm is learning! The current simulation is 80\n",
            "The current epsilon rate is 0.62\n",
            "The current epsilon rate is 0.59625\n",
            "Please wait, the algorithm is learning! The current simulation is 90\n",
            "The current epsilon rate is 0.5725\n",
            "The current epsilon rate is 0.5487500000000001\n",
            "Please wait, the algorithm is learning! The current simulation is 100\n",
            "The current epsilon rate is 0.525\n",
            "Please wait, the algorithm is learning! The current simulation is 110\n",
            "Please wait, the algorithm is learning! The current simulation is 120\n",
            "Please wait, the algorithm is learning! The current simulation is 130\n",
            "Please wait, the algorithm is learning! The current simulation is 140\n",
            "Please wait, the algorithm is learning! The current simulation is 150\n",
            "Please wait, the algorithm is learning! The current simulation is 160\n",
            "Please wait, the algorithm is learning! The current simulation is 170\n",
            "Please wait, the algorithm is learning! The current simulation is 180\n",
            "Please wait, the algorithm is learning! The current simulation is 190\n",
            "Please wait, the algorithm is learning! The current simulation is 200\n",
            "Please wait, the algorithm is learning! The current simulation is 210\n",
            "Please wait, the algorithm is learning! The current simulation is 220\n",
            "Please wait, the algorithm is learning! The current simulation is 230\n",
            "Please wait, the algorithm is learning! The current simulation is 240\n",
            "Please wait, the algorithm is learning! The current simulation is 250\n",
            "Please wait, the algorithm is learning! The current simulation is 260\n",
            "Please wait, the algorithm is learning! The current simulation is 270\n",
            "Please wait, the algorithm is learning! The current simulation is 280\n",
            "Please wait, the algorithm is learning! The current simulation is 290\n",
            "Please wait, the algorithm is learning! The current simulation is 300\n",
            "Please wait, the algorithm is learning! The current simulation is 310\n",
            "Please wait, the algorithm is learning! The current simulation is 320\n",
            "Please wait, the algorithm is learning! The current simulation is 330\n",
            "Please wait, the algorithm is learning! The current simulation is 340\n",
            "Please wait, the algorithm is learning! The current simulation is 350\n",
            "Please wait, the algorithm is learning! The current simulation is 360\n",
            "Please wait, the algorithm is learning! The current simulation is 370\n",
            "Please wait, the algorithm is learning! The current simulation is 380\n",
            "Please wait, the algorithm is learning! The current simulation is 390\n",
            "The simulation is done!\n",
            "qtable_disc_0.95_shap_0_pen_0_sims_400_batt_6_price_3_hour_3_action_3.npy is saved ...\n"
          ]
        }
      ],
      "source": [
        "#We can also train the Qagent with a decaying epsilon schedule\n",
        "config_file = open('../../../config.json')\n",
        "config = json.load(config_file)\n",
        "\n",
        "bin_size, properties, learning_rate = config['bin_size'], config['properties'], config['learning_rate']\n",
        "\n",
        "# num_battery_levels can be 6 11 26 51         => not test for now : 26, 51\n",
        "# num_actions can be 3, 5,                     => not test for now : 11, 21\n",
        "# num_hours can be 3, 4, 6, 12, 24             => not test for now : 12, 24\n",
        "# num price can be 3, 4, 5, 7, 11              => not test for now : 11\n",
        "\n",
        "env = StorageEnv(path_to_train_data=\"../../../data/train.xlsx\", num_actions=bin_size['action'], penalty_on=properties['penalties'])\n",
        "print(bin_size)\n",
        "print(properties)\n",
        "agent_epsilon_decay = QAgent(env, bin_size=bin_size, properties=properties)\n",
        "agent_epsilon_decay.train(learning_rate=learning_rate, adaptive_epsilon=True)\n",
        "agent_epsilon_decay.save_Q_table()\n",
        "\n",
        "# create file to store all rewards in if it doesnt exist yet\n",
        "if not os.path.isfile('train_rewards.txt'):\n",
        "    rewards = {}\n",
        "\n",
        "else:\n",
        "    # reading the rewards data from the file \n",
        "    with open('train_rewards.txt', 'r') as f:\n",
        "        data = f.read()\n",
        "        \n",
        "    # reconstructing the data as a dictionary \n",
        "    rewards = json.loads(data)\n",
        "\n",
        "# add current run to rewards dictionary\n",
        "rewards[agent_epsilon_decay.k] = [agent_epsilon_decay.num_simulations, agent_epsilon_decay.average_rewards]# agent_epsilon_decay.total_output\n",
        "\n",
        "# save new rewards dictionary to file\n",
        "with open('train_rewards.txt', 'w') as f: \n",
        "     f.write(json.dumps(rewards))\n",
        "\n",
        "\n",
        "\n",
        "# with open(filename, 'w') as f:\n",
        "#     json.dump(agent_epsilon_decay.total_rewards, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-8104.036310359155,\n",
              " -8239.50632478481,\n",
              " -8004.129106354274,\n",
              " -7752.931372943579,\n",
              " -7651.991542610931,\n",
              " -7388.716351701628,\n",
              " -6994.821326275045,\n",
              " -6718.589955481669,\n",
              " -6386.6734774777715,\n",
              " -6111.234481852866,\n",
              " -5727.810664252063,\n",
              " -5425.258481332048,\n",
              " -5046.100850360181,\n",
              " -4635.896735060733,\n",
              " -4282.60976723852,\n",
              " -3803.9402312763805,\n",
              " -3454.81203222385,\n",
              " -3014.4050962825377,\n",
              " -2596.289002231633,\n",
              " -2208.414607136122,\n",
              " -1767.5209700351152,\n",
              " -1591.9444131056805,\n",
              " -1616.6395005263137,\n",
              " -1595.0661434899234,\n",
              " -1608.8798719654844,\n",
              " -1594.964943868236,\n",
              " -1622.606838154888,\n",
              " -1591.6849899904769,\n",
              " -1589.3382297450348,\n",
              " -1630.5596323420195,\n",
              " -1608.283242780375,\n",
              " -1599.5135049287387,\n",
              " -1580.356421463574,\n",
              " -1614.9390891935377,\n",
              " -1590.0776311562795,\n",
              " -1642.6281657374434,\n",
              " -1583.49318354513,\n",
              " -1624.4930345420175,\n",
              " -1575.9520477801314,\n",
              " -1661.9809671131861]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_epsilon_decay.average_rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get notebook version from Wenhua\n",
        "# add reward saving properly with dict, make sure rewards from train and rewards/actions/battery levels from test are being saved\n",
        "# push main.py to github\n",
        "# run best config for all experiments\n",
        "# finish plottig functios\n",
        "# write report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 750x750 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "agent_epsilon_decay.visualize_rewards()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
